{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"nlp-class","language":"python","name":"nlp-class"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Prática Pre-Processamento.ipynb","provenance":[],"collapsed_sections":["wFER3k8KYe-F"]}},"cells":[{"cell_type":"code","metadata":{"id":"4ofFvi6aU2aT"},"source":["#Bibliotecas que precisam ser instaladas para a prática:\n","!pip install unidecode==1.2.0\n","!pip install wikipedia==1.4.0\n","!pip install spacy==2.2.4\n","!python -m spacy download en\n","!python -m spacy download pt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IxvjO-H9U2dt"},"source":["# Técnicas de Pré-processamento"]},{"cell_type":"code","metadata":{"id":"NUfsnZq9U2du","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621775468934,"user_tz":180,"elapsed":318,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"730931a5-7208-4fa5-b945-a496cc6a54d5"},"source":["import nltk\n","import wikipedia\n","import re\n","import spacy\n","from nltk.probability import FreqDist\n","nltk.download(\"stopwords\")\n","nltk.download('punkt')\n","nltk.download('rslp')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package rslp to /root/nltk_data...\n","[nltk_data]   Unzipping stemmers/rslp.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"Bl3qVdoaU2dw"},"source":["## Definindo o corpus\n","\n","Primeiramente, definimos o corpus que iremos trabalhar."]},{"cell_type":"code","metadata":{"id":"LObmG0e_U2dx"},"source":["# Caso o pacote wikipedia não funcione:\n","## Entre no link e faça downaload do arquivo https://drive.google.com/open?id=15R1jcugeM5SoGSPIPyG_6X6F3oMlxSBt\n","## Depois leia com o comando abaixo\n","#file = open(\"pln_wikipedia.txt\", 'r')\n","#file_wiki = file.readlines()\n","#file.close()\n","#corpus = '\\n'.join(file_wiki)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kN2IQNv5U2d1"},"source":["wikipedia.set_lang(\"pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EM8TiMU4U2d4"},"source":["pln = wikipedia.page(\"PLN\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0hGJ6HMtU2d6"},"source":["corpus = pln.content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EmSdONIGU2d_"},"source":["print(\"O texto que estamos utilizando é da URL\",pln.url)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EzO-lVIgU2eC"},"source":["print(pln.content)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8QdmSASmU2eF"},"source":["## Tokenização\n","\n","Existem várias formas de realizar tokenização. \n","1. Split()\n","2. Regex\n","3. NLTK\n","4. ..."]},{"cell_type":"markdown","metadata":{"id":"vpC8C-NfU2eG"},"source":["### Split\n","\n","Faça utilizando o método abaixo\n","<b> Não esqueça de armazenar o resultado na variável abaixo. </b>\n","\n","```python\n","str.split()\n","```"]},{"cell_type":"code","metadata":{"id":"CQWJf8eAU2eG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Evq4lIQNU2eM"},"source":["### Regex\n","\n","Faça utilizando o método abaixo\n","<b> Não esqueça de armazenar o resultado na variável abaixo. </b>\n","\n","```python\n","re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n","```"]},{"cell_type":"code","metadata":{"id":"gJOBqy-DU2eM"},"source":["tokens_regex = "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWrk8Rm0U2eS"},"source":["### NLTK\n","\n","Faça utilizando o método abaixo.\n","<b> Não esqueça de armazenar o resultado na variável abaixo. </b>\n","\n","```python\n","nltk.word_tokenize(corpus, language='portuguese')\n","```"]},{"cell_type":"code","metadata":{"id":"zHqORP70U2eT"},"source":["tokens_nltk = "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xufxGJpPU2eX"},"source":["def plot_frequencia_tokens(tokens):\n","    fd_words = FreqDist(tokens)\n","    fd_words.plot(20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fXdTpsjVU2eZ"},"source":["### Plot das tokenizações\n","\n","Plote o resultado de cada uma das tokenizações. \n","Utilize o método <b> plot_frequencia_tokens() </b> para plotar o gráfico.\n","Também imprima o <b> tamanho de cada tokenização </b>"]},{"cell_type":"code","metadata":{"id":"v7OOaS6Gew0m"},"source":["# Split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2IHVqfToexbE"},"source":["# Regex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLyGZtmhezER","executionInfo":{"status":"ok","timestamp":1621777667129,"user_tz":180,"elapsed":402,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}}},"source":["# NLTK"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JUOm1pgjU2ek"},"source":["Como foi possível observar, existem variações nas tokenizações realizadas. \n","A que gerou mais tokens foi a que utilizou regex.\n","Por isso iremos utilizá-la a partir deste ponto.\n","Utilize o resultado de <b> tokens_regex</b>."]},{"cell_type":"markdown","metadata":{"id":"GXN6naHeU2ek"},"source":["## Capitalização\n","\n","traforme todos os tokens para minúsculo utilizando a função abaixo:\n","\n","```python\n","str.lower()\n","```"]},{"cell_type":"code","metadata":{"id":"KgAOuq1sU2el"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GT44nJ72U2en"},"source":[" <b> <span style=\"color:red\"> Lembre de utilizar a VARIÁVEL que contém o resultado da transformação anterior </span> </b>"]},{"cell_type":"markdown","metadata":{"id":"NNBDXkVGU2en"},"source":["## Remoção Stopwords\n","\n","remova todas as stopwords retornadas pelo pacote NLTK da lista de tokens.\n","\n","```python\n","portugues_stops = stopwords.words('portuguese')\n","```\n","\n","Note que a variável \"portugues_stops\" é uma lista de palavras."]},{"cell_type":"code","metadata":{"id":"-vkUCUv2U2en"},"source":["from nltk.corpus import stopwords"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vG30zABU2ew"},"source":["tokens_sem_stop = "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PpsE73A3U2ey"},"source":["## Remoção Números\n","\n","remova todos os números, utilizando uma regex\n","\n","```python\n","re.sub(__,__,__)\n","```"]},{"cell_type":"code","metadata":{"id":"93QZ-mbOU2ez"},"source":["tokens_sem_numbers = "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZAziUGgxU2e0"},"source":["## Remoção Pontuação\n","\n","remova todas as pontruações retornadas pelo pacote string da lista de tokens.\n","\n","```python\n","string.punctuation\n","```"]},{"cell_type":"code","metadata":{"id":"-JPCj-lXU2e6"},"source":["tokens_sem_punction = "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SM-c--fZU2fB"},"source":["## Remoção Acentos\n","\n","remova todos os acentos utilizando a função abaixo:\n","\n","```python\n","unidecode(str)\n","```"]},{"cell_type":"code","metadata":{"id":"-m2wSusXU2fB"},"source":["from unidecode import unidecode"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H1q1I-UhU2fD"},"source":["tokens_sem_acentos = "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YdD-DyW-U2fF"},"source":["###  Plote a frequência dos tokens sem acentos. Utilize o método plot_frequencia_tokens() para plotar o gráfico. Também imprima o tamanho desta lista. "]},{"cell_type":"code","metadata":{"id":"RCyr8wlWU2fG","executionInfo":{"status":"ok","timestamp":1621777734017,"user_tz":180,"elapsed":222,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}}},"source":["# plot tokens_sem_acentos"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N0B2VMc2U2fM"},"source":["## Stemming\n","\n","Iremos utilizar o stemming da biblioteca NLTK. O algoritmo disponível para este procedimento em portugês é o RSLPStemmer.\n","\n","```python\n","stemmer = nltk.stem.RSLPStemmer()\n","```\n","\n","Aplique o stemmet em cada elemento da lista de tokens.\n"]},{"cell_type":"code","metadata":{"id":"sXsm_lS3U2fQ"},"source":["tokens_stemmer = "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PE9SWw5BU2fS"},"source":["###  Plote a frequência dos tokens após o processo de stemming. Utilize o método plot_frequencia_tokens() para plotar o gráfico. Também imprima o tamanho desta lista. "]},{"cell_type":"code","metadata":{"id":"aJhUtTaIfMQS"},"source":["# plot tokens_stemmer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vRj0sT4oU2fV"},"source":["## Lemmatization\n","a biblitoteca NLTK não possui lematização para português.\n","Mas a scpaCy possui."]},{"cell_type":"code","metadata":{"id":"x-oXoWovWrbt"},"source":["import pt_core_news_sm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFpQrNXQU2fV"},"source":["#carrega o modelo para português\n","nlp = pt_core_news_sm.load()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hBslXKwlU2fY"},"source":["A primeira etapa para executar a lematização é transformar a lista de tokens para uma string. \n","Utilize a variável de tokens: <b> tokens_sem_punction </b>.\n","Você pode executar a <b> lematização </b> com acentos ou sem acentos. Funciona da mesma forma.\n","\n","Dica: utilize o método join para isto:\n","\n","```python\n","str.join(list)\n","\n","```"]},{"cell_type":"code","metadata":{"id":"DAo25jkFU2fY"},"source":["str_tokens = ' '.join(tokens_sem_punction)\n","#str_tokens = ' '.join(tokens_sem_acentos)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aNTknXsLU2fb"},"source":["Depois carregue a string de tokens (<b>str_tokens</b>) no modelo <b> nlp </b>, carregado em um dos passos anteriores.\n","\n","```python\n","doc = nlp(str_tokens)\n","```"]},{"cell_type":"code","metadata":{"id":"BchCPaZTU2fb"},"source":["doc = "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9uXzFRLWU2fd"},"source":["Verifique o tipo da variável <b> doc </b>.\n","Observe que é do tipo spacy.tokens.doc.Doc"]},{"cell_type":"code","metadata":{"id":"cnxBJgCiU2fd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621775624981,"user_tz":180,"elapsed":310,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"c421c5be-7c6d-4a4f-8a7e-9ffad7ac9ac2"},"source":["type(doc)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["spacy.tokens.doc.Doc"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"MU495FKpU2ff"},"source":["Como tipo da variável doc é do tipo spacy.tokens.doc.Doc.\n","Apenas é preciso iterar em cada token e retornar o atributo <b> lemma_</b>"]},{"cell_type":"code","metadata":{"id":"0jOWhl2WU2fg"},"source":["tokens_lemm = "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EOUMZMmuU2fm"},"source":["###  Plote a frequência dos tokens após o processo de lematização. Utilize o método plot_frequencia_tokens() para plotar o gráfico. Também imprima o tamanho desta lista. "]},{"cell_type":"code","metadata":{"id":"MpgeBZnBfYU-"},"source":["# plot tokens_lemm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-XLXgdESYG-J"},"source":["# Outras bibliotecas para pré-processamento"]},{"cell_type":"markdown","metadata":{"id":"wFER3k8KYe-F"},"source":["## Texhero\n","\n","https://texthero.org/"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":955},"id":"rcyWSM2vYLW3","executionInfo":{"status":"ok","timestamp":1621777339109,"user_tz":180,"elapsed":3155,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"569d0fc2-07ac-4c85-acf1-79c747f57445"},"source":["!pip install texthero==1.0.9"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting texthero==1.0.9\n","  Using cached https://files.pythonhosted.org/packages/1f/5a/a9d33b799fe53011de79d140ad6d86c440a2da1ae8a7b24e851ee2f8bde8/texthero-1.0.9-py3-none-any.whl\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from texthero==1.0.9) (0.22.2.post1)\n","Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.7/dist-packages (from texthero==1.0.9) (4.41.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from texthero==1.0.9) (1.19.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from texthero==1.0.9) (2.2.4)\n","Requirement already satisfied: gensim>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from texthero==1.0.9) (3.6.0)\n","Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from texthero==1.0.9) (3.2.2)\n","Requirement already satisfied: unidecode>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from texthero==1.0.9) (1.2.0)\n","Requirement already satisfied: plotly>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from texthero==1.0.9) (4.4.1)\n","Requirement already satisfied: wordcloud>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from texthero==1.0.9) (1.5.0)\n","Requirement already satisfied: nltk>=3.3 in /usr/local/lib/python3.7/dist-packages (from texthero==1.0.9) (3.6.2)\n","Requirement already satisfied: pandas>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from texthero==1.0.9) (1.1.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->texthero==1.0.9) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->texthero==1.0.9) (1.4.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero==1.0.9) (1.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero==1.0.9) (1.0.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero==1.0.9) (1.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero==1.0.9) (56.1.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero==1.0.9) (2.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero==1.0.9) (0.8.2)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero==1.0.9) (7.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero==1.0.9) (3.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero==1.0.9) (1.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero==1.0.9) (2.23.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->texthero==1.0.9) (0.4.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.6.0->texthero==1.0.9) (5.0.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.6.0->texthero==1.0.9) (1.15.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero==1.0.9) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero==1.0.9) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero==1.0.9) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero==1.0.9) (1.3.1)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.2.0->texthero==1.0.9) (1.3.3)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud>=1.5.0->texthero==1.0.9) (7.1.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero==1.0.9) (2019.12.20)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero==1.0.9) (8.0.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.2->texthero==1.0.9) (2018.9)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero==1.0.9) (4.0.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero==1.0.9) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero==1.0.9) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero==1.0.9) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero==1.0.9) (2.10)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero==1.0.9) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero==1.0.9) (3.4.1)\n","Installing collected packages: texthero\n","  Found existing installation: texthero 1.0\n","    Uninstalling texthero-1.0:\n","      Successfully uninstalled texthero-1.0\n","Successfully installed texthero-1.0.9\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["texthero"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"1PUyIqqga_e4"},"source":["import texthero as hero\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gQJUm1hNYn9w"},"source":["texto = \\\n","\"\"\"A história      do PLN (Processamento de linguagem Natural) começou na década de 1950, quando Alan Turing publicou o artigo Computing Machinery and Intelligence. \n","Fonte: https://pt.wikipedia.org/wiki/Processamento_de_linguagem_natural \"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"c0AY96x7ZO9G","executionInfo":{"status":"ok","timestamp":1621777172034,"user_tz":180,"elapsed":13,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"6df06b21-768c-4ba4-eae3-ae48bc3c7e0c"},"source":["texto"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'A história      do PLN (Processamento de linguagem Natural) começou na década de 1950, quando Alan Turing publicou o artigo Computing Machinery and Intelligence. \\nFonte: https://pt.wikipedia.org/wiki/Processamento_de_linguagem_natural '"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"uM3NUA3UbFqR"},"source":["texto = pd.Series(texto)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHHOhON2dMbm","executionInfo":{"status":"ok","timestamp":1621777261027,"user_tz":180,"elapsed":224,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"e9b937bf-ab8c-4441-b3e0-5c365c247ee4"},"source":["#Aplica tokenização\n","hero.tokenize(texto).values[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['A',\n"," 'história',\n"," 'do',\n"," 'PLN',\n"," '(',\n"," 'Processamento',\n"," 'de',\n"," 'linguagem',\n"," 'Natural',\n"," ')',\n"," 'começou',\n"," 'na',\n"," 'década',\n"," 'de',\n"," '1950',\n"," ',',\n"," 'quando',\n"," 'Alan',\n"," 'Turing',\n"," 'publicou',\n"," 'o',\n"," 'artigo',\n"," 'Computing',\n"," 'Machinery',\n"," 'and',\n"," 'Intelligence',\n"," '.',\n"," 'Fonte',\n"," ':',\n"," 'https',\n"," ':',\n"," '/',\n"," '/',\n"," 'pt.wikipedia.org/wiki/Processamento',\n"," '_',\n"," 'de',\n"," '_',\n"," 'linguagem',\n"," '_',\n"," 'natural']"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"woEW8go1awYr","executionInfo":{"status":"ok","timestamp":1621777175022,"user_tz":180,"elapsed":10,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"c0941386-1211-40db-d1a9-649bb992d8b3"},"source":["#Remove numeros\n","hero.remove_digits(texto).values[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'A história      do PLN (Processamento de linguagem Natural) começou na década de  , quando Alan Turing publicou o artigo Computing Machinery and Intelligence. \\nFonte: https://pt.wikipedia.org/wiki/Processamento_de_linguagem_natural '"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"Y4Snd94tbAKg","executionInfo":{"status":"ok","timestamp":1621777175919,"user_tz":180,"elapsed":22,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"41ee9534-2ae3-48c7-f8b6-c33b266bddcd"},"source":["#Remove pontuação\n","hero.remove_punctuation(texto).values[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'A história      do PLN  Processamento de linguagem Natural  começou na década de 1950  quando Alan Turing publicou o artigo Computing Machinery and Intelligence  \\nFonte  https pt wikipedia org wiki Processamento de linguagem natural '"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"N_LnU83Nbqvi","executionInfo":{"status":"ok","timestamp":1621777180893,"user_tz":180,"elapsed":236,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"91a494f7-771f-416a-b60f-418861eb2756"},"source":["#Remove parênteses\n","hero.remove_brackets(texto).values[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'A história      do PLN  começou na década de 1950, quando Alan Turing publicou o artigo Computing Machinery and Intelligence. \\nFonte: https://pt.wikipedia.org/wiki/Processamento_de_linguagem_natural '"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"v4neqZ-_b2z4","executionInfo":{"status":"ok","timestamp":1621777182200,"user_tz":180,"elapsed":231,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"6bd0a961-7cc9-42a2-8ea2-ba3d1d45d8e8"},"source":["#Remove espaços em brancos\n","hero.remove_whitespace(texto).values[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'A história do PLN (Processamento de linguagem Natural) começou na década de 1950, quando Alan Turing publicou o artigo Computing Machinery and Intelligence. Fonte: https://pt.wikipedia.org/wiki/Processamento_de_linguagem_natural'"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"JnhY3alVbzV-","executionInfo":{"status":"ok","timestamp":1621777186580,"user_tz":180,"elapsed":320,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"16f07676-fd5f-4b5c-e55a-d1049774941c"},"source":["#Remove stopwords\n","portugues_stops = stopwords.words('portuguese')\n","hero.remove_stopwords(texto, portugues_stops).values[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'A história       PLN (Processamento  linguagem Natural) começou  década  1950,  Alan Turing publicou  artigo Computing Machinery and Intelligence. \\nFonte: https://pt.wikipedia.org/wiki/Processamento_de_linguagem_natural '"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"3y0S3_GkcHoc","executionInfo":{"status":"ok","timestamp":1621777219759,"user_tz":180,"elapsed":530,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"6d576a2c-00a6-4ad0-f1d3-54a4dc2eed96"},"source":["#Remove URL\n","hero.remove_urls(texto).values[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'A história      do PLN (Processamento de linguagem Natural) começou na década de 1950, quando Alan Turing publicou o artigo Computing Machinery and Intelligence. \\nFonte:   '"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"BXjdNzDrfqxF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kWT1Es2jfrtz"},"source":["## Clean-Text\n","\n","https://github.com/jfilter/clean-text"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SjstQC5Ef75_","executionInfo":{"status":"ok","timestamp":1621777979656,"user_tz":180,"elapsed":3078,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"19d69ad4-e778-4dbb-e8cb-5cecd3297166"},"source":["!pip install clean-text==0.4.0"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: clean-text==0.4.0 in /usr/local/lib/python3.7/dist-packages (0.4.0)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (from clean-text==0.4.0) (1.2.0)\n","Requirement already satisfied: ftfy<7.0,>=6.0 in /usr/local/lib/python3.7/dist-packages (from clean-text==0.4.0) (6.0.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0,>=6.0->clean-text==0.4.0) (0.2.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8DHK-hLigByp","executionInfo":{"status":"ok","timestamp":1621778018904,"user_tz":180,"elapsed":692,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"e23ba848-bf04-4008-d4c8-8fbaf317395b"},"source":["from cleantext import clean"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Zf042_kqgFBW","executionInfo":{"status":"ok","timestamp":1621778018907,"user_tz":180,"elapsed":13,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}}},"source":["texto = \\\n","\"\"\"A história      do PLN (Processamento de linguagem Natural) começou na década de 1950, quando Alan Turing publicou o artigo Computing Machinery and Intelligence. \n","Fonte: https://pt.wikipedia.org/wiki/Processamento_de_linguagem_natural \"\"\""],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"9LJ_H-Xtftge","executionInfo":{"status":"ok","timestamp":1621778077038,"user_tz":180,"elapsed":309,"user":{"displayName":"Bárbara Silveira Fraga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRSYKhKST3-JxDhaPKtydW_1gnhsEFC_X_IjaV=s64","userId":"08155615283259294201"}},"outputId":"c013ffca-216c-4d59-b125-72db9950067f"},"source":["clean(texto,\n","    fix_unicode=True,              \n","    to_ascii=True,                 \n","    lower=True,                    \n","    no_line_breaks=False,\n","    no_urls=True,\n","    no_emails=False,     \n","    no_phone_numbers=False,\n","    no_numbers=True,      \n","    no_digits=True,       \n","    no_currency_symbols=False, \n","    no_punct=True,          \n","    replace_with_punct=\"\",\n","    replace_with_url=\"<URL>\",\n","    replace_with_email=\"<EMAIL>\",\n","    replace_with_phone_number=\"<PHONE>\",\n","    replace_with_number=\"<NUMBER>\",\n","    replace_with_digit=\"0\",\n","    replace_with_currency_symbol=\"<CUR>\",\n","    lang=\"pt\"\n",")"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'a historia do pln processamento de linguagem natural comecou na decada de <number> quando alan turing publicou o artigo computing machinery and intelligence\\nfonte <url>'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"_WdneJxXgJQJ"},"source":[""],"execution_count":null,"outputs":[]}]}