{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformação de dados.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PjKEBdGTynHd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transformação de dados\n",
        "\n",
        "Código em Python para análise de dados. \n",
        "\n",
        "\n",
        "Este notebook foi desenvolvido para o ambiente GOOGLE COLAB ([colab.research.google.com](https://colab.research.google.com)).\n",
        "\n",
        "Prof. Hugo de Paula\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gUYY894Qylai",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inicialização da plataforma\n",
        "\n",
        "A célula a seguir inicializa a plataforma, carregando as bibliotecas que serão relevantes para o trabalho em seguida.\n",
        "\n",
        "## Bibliotecas\n",
        "\n",
        "\n",
        "\n",
        "```numpy``` -- usada para processamento numérico.\n",
        "\n",
        "```pandas``` -- usada para manipulação de bases de dados.\n",
        "\n",
        "```pyplot``` -- usada para visualização de dados.\n",
        "\n",
        "```seaborn``` -- usada para visualização de dados.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "NyeTED-9zxTC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "np.set_printoptions(threshold=None, precision=2)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('precision', 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qbw3Lal73we2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Base de dados do Titanic\n",
        "\n",
        "Essa base de dados pode ser obtida no Kaggle, no endereço: \n",
        "[www.kaggle.com/c/titanic/data](https://www.kaggle.com/c/titanic/data)\n",
        "\n",
        "### DESCRIÇÃO DOS ATRIBUTOS:\n",
        "\n",
        "\n",
        "*   ```survival``` --  Sobrevivente (0 = Não; 1 = Sim)\n",
        "*   ```pclass``` --  Classe do passageiro (1 = 1a classe; 2 = 2a classe; 3 = 3a classe)\n",
        "*   ```name``` --  Nome (str)\n",
        "*   ```sex``` --  Sexo (male; female)\n",
        "*   ```age``` --  Idade (numérica)\n",
        "*   ```sibsp``` --  Número de irmãos/conjuges à bordo\n",
        "*   ```parch``` --  Número de pais/filhos à bordo\n",
        "*   ```ticket``` --  Número da passagem\n",
        "*   ```fare``` --  Tarifa do passageiro\n",
        "*   ```cabin``` --  Cabine\n",
        "*   ```embarked``` --  Porto de embarque (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
        "\n",
        "### UPLOAD DE ARQUIVO LOCAL:\n",
        "\n",
        "Para fazer o upload de bases de dados, deve-se usar o objeto ```files``` do pacote ```goggle.colab```.\n",
        "\n",
        "Deve-se fazer o upload do arquivo \"train.csv\" disponível na pasta \"Datasets\\Titanic\".\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "XTPbeWe14a29",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oy1UjWsm5udo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "titanic_train = pd.read_csv(next(iter(uploaded.keys())))\n",
        "\n",
        "print(\"\\nDimensões de Titanic:\\n{0}\\n\".format(titanic_train.shape))\n",
        "print(\"\\nCampos de Titanic:\\n{0}\\n\".format(list(titanic_train.keys())))\n",
        "print(\"\\nTipos dos dados:\\n{0}\\n\".format(titanic_train.dtypes))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-VxLKNs8-lP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ESTATÍSTICA DESCRITIVA DOS DADOS\n",
        "\n",
        "O comando describe exibe prioritariamente os campos numéricos. Deve-se isolar os campos categóricos para serem exibidos posteriormente."
      ]
    },
    {
      "metadata": {
        "id": "4aCdL67o8-G_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Exibe apenas os campos numméricos:\n",
        "\n",
        "print(titanic_train.describe())\n",
        "\n",
        "# Para se ter uma visão dos atributos categóricos, os atributos não numéricos \n",
        "# são descartados. \n",
        "\n",
        "categ = titanic_train.dtypes[titanic_train.dtypes == \"object\"].index\n",
        "\n",
        "print(\"\\n\", titanic_train[categ].describe(), sep='\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1G0l6X1s970Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### REMOÇÃO DE ATRIBUTOS IRRELEVANTES\n",
        "\n",
        "Os atributos ```survival``` (objetivo ou label), e atributos que descrevem os passageiros ou os agrupam em categorias são úteis e serão mantidos, por exemplo: ```Pclass```, ```Sex```, ```Age```, ```SibSp```, ```Parch```, ```Fare``` e ```Embarked```. \n",
        "\n",
        "\n",
        "* ```passengerId``` é apenas uma chave primária para identificar um passageiro e não é relevante para o problema.\n",
        "\n",
        "* ```Name``` náo é útil para previsão, mas pode ser útil para identificação dos registros ou pós-processamento (por exemplo, extrair o último nome).\n",
        "\n",
        "* ```Ticket``` não identifica o registro e nem descreve o passageiro, por isso, deve ser removido.\n",
        "\n",
        "* ```Cabin``` não identifica bem os passageiros, mas pode ser útil utilizarmos o padrão letra+numero para descrever os passageiros pelo andar do local da cabine."
      ]
    },
    {
      "metadata": {
        "id": "0KheF1X787au",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del titanic_train[\"PassengerId\"]\n",
        "del titanic_train[\"Ticket\"]\n",
        "\n",
        "# Verifique que o número de atributos reduziu para 10.\n",
        "\n",
        "print(\"\\nDimensões de Titanic:\\n{0}\\n\".format(titanic_train.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EDYqKkY1_h3I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TRANSFORMAÇÃO DE VARIÁVEIS\n",
        "\n",
        "#### Converter numérico em categórico.\n",
        "\n",
        "Variáveis categóricas codificadas numericamente possuem baixa legibilidade. Portanto, podem ser candidatas a serem recodificadas."
      ]
    },
    {
      "metadata": {
        "id": "93BwzY_lABKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# OBSERVAÇÃO: se a base for usada para a competição do kaggle, o atributo\n",
        "# alvo, que é o campo 'survived' não deve ser recodificada.\n",
        "\n",
        "new_survived = pd.Categorical(titanic_train[\"Survived\"])\n",
        "new_survived = new_survived.rename_categories([\"Morreu\",\"Sobreviveu\"])              \n",
        "titanic_train[\"Survided\"] = new_survived\n",
        "\n",
        "new_Pclass = pd.Categorical(titanic_train[\"Pclass\"], ordered=True)\n",
        "new_Pclass = new_Pclass.rename_categories([\"1aClasse\",\"2aClasse\",\"3aClasse\"])     \n",
        "titanic_train[\"Pclass\"] = new_Pclass\n",
        "\n",
        "print(\"\\nTipos dos dados:\\n{0}\\n\".format(titanic_train.dtypes))\n",
        "categ = titanic_train.dtypes[titanic_train.dtypes == \"category\"].index\n",
        "print(\"\\n\", titanic_train[categ].describe(), sep='\\n')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HTBozOeBBWV5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Converter atributo através de processamento de string (usando *list comprehension*).\n",
        "\n",
        "No atributo ```Cabin```,  parece que o padrão letra+número (veja exibição a seguir) indica que uma cabine pertence a algum andar, ou nível. Podemos agrupar o atributo Cabin pela letra inicial da cabine.\n"
      ]
    },
    {
      "metadata": {
        "id": "fRAcW-BSA0Yl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Exibe valores únicos\n",
        "\n",
        "print(\"\\nValores únicos do atributo Cabin:\",titanic_train[\"Cabin\"].unique(), sep='\\n')\n",
        "\n",
        "# Converte o dado para String\n",
        "\n",
        "char_cabin = titanic_train[\"Cabin\"].astype(str)\n",
        "\n",
        "# Pega apenas a primeira letra\n",
        "\n",
        "new_cabin = pd.Categorical([cabin[0] for cabin in char_cabin])\n",
        "titanic_train[\"Cabin\"] = new_cabin\n",
        "\n",
        "print(\"\\nValores únicos do atributo Cabin:\",titanic_train[\"Cabin\"].unique(), sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7npsJkQoDpZp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### VALORES OMISSOS OU INCONSISTENTES\n",
        "\n",
        "Em atributos numéricos , as possibilidades são:\n",
        "\n",
        "1. substituir por zeros;\n",
        "2. substituir por um valor médio ou mediano;\n",
        "3. estimar valores usando modelos estatísticos ou preditivos;\n",
        "4. particionar a base em registros completos e registros incompletos.\n",
        "\n",
        "Vamos analisar o atributo ```Age``` para tratarmos os valores omissos."
      ]
    },
    {
      "metadata": {
        "id": "1pvbAVQYEXPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "titanic_train.hist(column='Age',    # Coluna a ser plotada\n",
        "                   figsize=(9,6),   # Tamanho do gráfico\n",
        "                   bins=20)         # Numero de colunas do histogram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t5z8F12WEe-R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O dado possui uma distribuição próxima da distribuição Normal. Vamos usar a mediana para preencher os valores faltantes."
      ]
    },
    {
      "metadata": {
        "id": "T6jgzUiNEp6O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mediana = np.median([el for el in titanic_train[\"Age\"] if (np.isnan(el) == False)])\n",
        "\n",
        "new_age = np.where(titanic_train[\"Age\"].isnull(), # condição\n",
        "                   mediana,                       # valor se verdadeiro\n",
        "                   titanic_train[\"Age\"])          # valor se falso\n",
        "titanic_train[\"Age\"] = new_age\n",
        "\n",
        "print(\"\\nAnálise do novo atributo Age:\")\n",
        "print(titanic_train[\"Age\"].describe())\n",
        "\n",
        "titanic_train.hist(column='Age',    # Coluna a ser plotada\n",
        "                   figsize=(9,6),   # Tamanho do gráfico\n",
        "                   bins=20)         # Numero de colunas do histogram\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LDZV3WXrFBNM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### DETECTANDO OUTLIERS\n",
        "\n",
        "Outliers são valores extremos. A estatística descritiva, em geral, provê um bom indicativo da presença de outliers, com valores máximos e mínimo muito distantes; o valor da média muito próximo de um máximo ou mínimo, mostrando problema de distribuição dos dados."
      ]
    },
    {
      "metadata": {
        "id": "YV71iH7jFKVu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "titanic_train[\"Fare\"].plot(kind=\"box\", figsize=(9,9))\n",
        "\n",
        "index = np.where(titanic_train[\"Fare\"] == max(titanic_train[\"Fare\"]) )\n",
        "\n",
        "print(\"Registros com valores extremos:\",titanic_train.loc[index], sep='\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xqK5TLz_Fun9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CRIANDO NOVOS ATRIBUTOS\n",
        "\n",
        "Vamos criar uma nova variável ```Family```, que irá unir, conjude e irmãos (```SibSp```) com pais e filhos (```Parch```)."
      ]
    },
    {
      "metadata": {
        "id": "5qaPm_z1F-Qj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "titanic_train[\"Family\"] = titanic_train[\"SibSp\"] + titanic_train[\"Parch\"]\n",
        "\n",
        "# Encontrando quem tem a maior família À bordo\n",
        "\n",
        "most_family = np.where(titanic_train[\"Family\"] == max(titanic_train[\"Family\"]))\n",
        "\n",
        "print(\"\\nAs maiores famílias à bordo:\\n{0}\".format(titanic_train.loc[most_family]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "actaCNc3GR-k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Os atributos agora estão redundantes, ou muito correlacionados, como podemos ver com a matriz de correlação. A matriz só funciona com tipos de ddos numéricos. Será possível perceber que a variável ```Family``` terá forte correlação (acima de 0.75) com ```SibSp``` e ```Parch```."
      ]
    },
    {
      "metadata": {
        "id": "iXf79w1zGX-N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int_fields = titanic_train.dtypes[titanic_train.dtypes == \"int64\"].index\n",
        "corr = np.corrcoef(titanic_train[int_fields].transpose())\n",
        "correlacao = pd.DataFrame(data=corr, index=int_fields, columns=int_fields)\n",
        "\n",
        "print(\"\\nMatriz de correlação dos atributos inteiros:\\n{0}\".format(correlacao))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5iuM7XVFHghH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Base de dados do Gazola de imóveis em São Paulo\n",
        "\n",
        "A base possui 14 campos: um identificador, 11 atributos e 2 rótulos (Cub e Preço $).\n",
        "\n",
        "### UPLOAD DE ARQUIVO LOCAL:\n",
        "\n",
        "Deve-se fazer o upload do arquivo \"Gazola_dados_apartamento_resumo.xls\" disponível na pasta \"Datasets\".\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mOVJOwJcHlg2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aTTz3rulH_5F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gazola = pd.read_excel(next(iter(uploaded.keys())), sheet_name=1)\n",
        "\n",
        "print(\"\\nDimensões:\\n{0}\\n\".format(gazola.shape))\n",
        "print(\"\\nCampos:\\n{0}\\n\".format(list(gazola.keys())))\n",
        "print(\"\\nTipos dos dados:\\n{0}\\n\".format(gazola.dtypes))\n",
        "print(gazola.describe(percentiles=[]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DefoRATFJEIW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PREPARANDO A BASE PARA O TREINAMENTO\n",
        "\n",
        "É necessário remover o identificador, retirar o Cub e definir o preço como atributo alvo.\n",
        "\n",
        "```train_test_split``` irá separar a base em \"base de treinamento\" e \"base de teste\" a partir de uma amostragem aleatória.\n"
      ]
    },
    {
      "metadata": {
        "id": "JjuMAt7lJPsS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = gazola.iloc[:,1:(gazola.shape[1] - 2)]\n",
        "\n",
        "y = gazola.iloc[:,(gazola.shape[1] - 1)]\n",
        "\n",
        "# Recupera os nomes dos atributos\n",
        "\n",
        "atributos = list(gazola)[1:(gazola.shape[1] - 2)]\n",
        "rotulo = list(gazola)[(gazola.shape[1] - 1)]\n",
        "\n",
        "# Exibe o histograma dos atributos.\n",
        "\n",
        "fig, ax = plt.subplots(2, 3, figsize=(10, 6))\n",
        "plt.suptitle(\"Histograma dos atributos\")\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        ax[i, j].hist(X.iloc[:,(i*3 + j)], label=atributos[i*3+j], bins=30)\n",
        "        ax[i, j].legend()\n",
        "\n",
        "fig, ax = plt.subplots(2, 3, figsize=(10, 6))\n",
        "plt.suptitle(\"Histograma dos atributos\")\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        if j == 2 and i == 1:\n",
        "            ax[i, j].hist(y.iloc[:],label=rotulo,bins=30)\n",
        "        else:            \n",
        "            ax[i, j].hist(X.iloc[:,(i*3 + j+6)],label=atributos[i*3 + j+6], bins=30)\n",
        "        ax[i, j].legend()\n",
        "\n",
        "\n",
        "# Amostragem de dados\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "\n",
        "print(\"Base de treinamento:{0}\".format(X_train.shape))\n",
        "print(\"Base de teste:{0}\".format(X_test.shape))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wkYibP01KlDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TREINAMENTO POR REGRESSÃO LINEAR\n",
        "\n",
        "```fit()``` realiza o ajusto do modelo (treinamento).\n",
        "\n",
        "```predict()``` aplica o modelo sobre novos dados.\n"
      ]
    },
    {
      "metadata": {
        "id": "RJuZS1WkK5s2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lnr = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "y_prev = lnr.predict(X_test)\n",
        "\n",
        "print(\"Acurácia da base de treinamento: {:.2f}\".format(lnr.score(X_train, y_train)))\n",
        "print(\"Acurácia da base de testes: {:.2f}\".format(lnr.score(X_test, y_test)))\n",
        "print(\"Descrição do modelo: \")\n",
        "s = [\"{0}: {1:0.2f}\".format(a, v) for a, v in zip(atributos, lnr.coef_)]\n",
        "print(\"w: {}  b: {:.2f}\".format(s, lnr.intercept_))\n",
        "print(\"Número de atributos usados: {}\".format(np.sum(lnr.coef_ != 0)))\n",
        "\n",
        "# Calcula o erro absoluto e o erro percentual da regressao linear\n",
        "errolnr = np.abs(y_test - y_prev)\n",
        "erroperc = errolnr / list(y_test)\n",
        "\n",
        "print('Erro percentual:\\n Média: {0:.2f}  Max: {1:.2f}   Min: {2:.2f}'\n",
        "      .format(np.mean(erroperc), np.max(erroperc), np.min(erroperc)))\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.errorbar(np.arange(y_test.size), list(y_test), yerr=errolnr,\n",
        "             fmt='.', ecolor='r', capsize=3)\n",
        "plt.title(\"Valores reais (barras de erro de predição)\")\n",
        "plt.grid()\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(7, 4))\n",
        "plt.suptitle(\"Erros de previsão\")\n",
        "ax[0].plot(errolnr,'.')\n",
        "ax[0].set_xlabel(\"Erro absoluto\")\n",
        "ax[0].grid()\n",
        "ax[1].plot(erroperc,'.')\n",
        "ax[1].set_xlabel(\"Erro percentual\")\n",
        "ax[1].grid()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rdqPARNoMgkS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TRANSFORMAÇÃO DE DADOS NUMÉRICOS\n",
        "\n",
        "Vamos explorar a transformação de dados, para resolver problemas de distribuição e a normalização de dados."
      ]
    },
    {
      "metadata": {
        "id": "jJmfmRsqMsp3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Os atributos possuem faixas de valores diferentes, que influencia os pesos \n",
        "# dos coeficientes da regressão. Vamos trabalhar melhor os atributos.\n",
        "\n",
        "X_scale = X\n",
        "\n",
        "# Iremos aplicar o logaritmo em \"Energia total\", \"Área total\" e \"Preço $\".\n",
        "\n",
        "X_scale['Energia'] = np.log10(X['Energia'])\n",
        "X_scale['Artot'] = np.log10(X['Artot'])\n",
        "y_scale = np.log10(y)\n",
        "\n",
        "# Normalização Min-Max dos dados.\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X_scale)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(6, 4))\n",
        "ax[0].hist(y,bins=30, label='Preço $')\n",
        "ax[0].set_title('Preço $')\n",
        "ax[1].hist(y_scale,bins=30, label='log10(Preço $)')\n",
        "ax[1].set_title('log_10(Preço $)')\n",
        "\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_scale, y_scale, test_size=0.1, random_state=0)\n",
        "\n",
        "lnr2 = LinearRegression().fit(X_train2, y_train2)\n",
        "\n",
        "y_prev2 = lnr2.predict(X_test2)\n",
        "\n",
        "errolnr2 = np.abs(y_test2 - y_prev2)\n",
        "errolnr2perc = np.abs(y_test2 - y_prev2)/y_test2\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(erroperc,'o', label='Regressão com atrib. originais')\n",
        "plt.plot(errolnr2perc,'o', label='Regressão com atrib. normalizados')\n",
        "plt.title(\"Erro de previsão (em %)\")\n",
        "plt.legend()\n",
        "\n",
        "print(\"\\n--------------- Regressão Linear Normalizada ---------------\")\n",
        "print(\"Acurácia da base de treinamento: {:.2f}\".format(lnr2.score(X_train2, y_train2)))\n",
        "print(\"Acurácia da base de testes: {:.2f}\".format(lnr2.score(X_test2, y_test2)))\n",
        "print(\"Descrição do modelo: \")\n",
        "s = [\"{0}: {1:0.2f}\".format(a, v) for a, v in zip(atributos, lnr2.coef_)]\n",
        "print(\"w: {}  b: {:.2f}\".format(s, lnr2.intercept_))\n",
        "\n",
        "\n",
        "print(\"\\n------------------  Comparação de pesos   ------------------\")\n",
        "s = [\"{0}: {1:0.2f}\".format(a, v) for a, v in zip(atributos, lnr.coef_)]\n",
        "print(\"Original:\\n w: {}  b: {:.2f}\".format(s, lnr.intercept_))\n",
        "s = [\"{0}: {1:0.2f}\".format(a, v) for a, v in zip(atributos, lnr2.coef_)]\n",
        "print(\"Normalizado:\\n w: {}  b: {:.2f}\".format(s, lnr2.intercept_))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}