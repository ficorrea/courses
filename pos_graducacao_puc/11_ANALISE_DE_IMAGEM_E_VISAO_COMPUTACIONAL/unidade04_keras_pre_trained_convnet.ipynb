{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unidade03_keras_pre-trained_convnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvobS2KMcmeC"
      },
      "source": [
        "**Utilizando rede pré-treinada**\n",
        "\n",
        "Uma rede pré-treinada é uma rede salva que tenha sido anteriormente treinada em um grande dataset, geralmente em uma tarefa de classificação de imagem em larga escala. \n",
        "\n",
        "Se esse conjunto de dados original for grande o suficiente e geral o suficiente, as features aprendidas pela rede pré-treinada pode atuar efetivamente como um modelo genérico e podem ser úteis para muitos problemas diferentes de visão computacional\n",
        "\n",
        "Por exemplo, pode-se treinar uma rede no ImageNet (onde as classes são principalmente animais e objetos do cotidiano) e, em seguida, redirecionar essa rede treinada para algo mais específico. \n",
        "\n",
        "Aqui, vamos considerar uma grande convnet treinada do dataset ImageNet (1,4 milhão de imagens rotuladas e 1000 classes diferentes). O ImageNet contém muitas classes de animais, incluindo diferentes espécies de cães e gatos (nosso objetivo)\n",
        "\n",
        "Usaremos a arquitetura VGG16, desenvolvida por Karen Simonyan e Andrew Zisserman em 2014, uma arquitetura de convnet simples e amplamente usada para o ImageNet. \n",
        "\n",
        "Há duas maneiras de aproveitar uma rede pré-treinada: extração de features e fine tuning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1_8a6t5e3K0"
      },
      "source": [
        "**Extração de features**\n",
        "\n",
        "Utiliza as representações aprendidas por uma rede anterior para extrair features de novas amostras. Estas features são executadas através de um novo classificador, treinado a partir do zero.\n",
        "\n",
        "Lembre-se que as convnet usadas para classificação são divididas em duas partes: camadas convolucionais e de pooling para extração de features (chamada de base convolucional) e camadas densas para classificação. \n",
        "\n",
        "Normalmente, as features aprendidas pelas camadas convolucionais são mais genéricas e reutilizáveis (as representações aprendidas pelas camadas densass de classificação são mais específicas e não devem ser reutilizadas).\n",
        "\n",
        "Vamos usar a base convolucional da rede VGG16, treinada no ImageNet, para extrair features de imagens de gatos e cães e, em seguida, treinar um classificador de gato versus cachorro sobre essas features.\n",
        "\n",
        "O modelo VGG16, entre outros, vem pré-embalado com Keras. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvqHSpAFbsSw"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(150, 150, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN93JR8bg6bc"
      },
      "source": [
        "Argumentos:\n",
        "\n",
        "**weights**, de onde queremos inicializar o modelo\n",
        "\n",
        "**include_top**, se refere à inclusão ou não do classificador densely-connected na parte superior da rede. Por padrão, esse classificador densely-connected corresponderia às 1000 classes do ImageNet. Como pretendemos usar nosso próprio classificador densely-connected (com apenas duas classes, gato e cachorro), não vamos incluí-lo.\n",
        "\n",
        "**input_shape**, o formato dos tensores de imagem (opcional). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a1MlQhnhvSk"
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw6X_LV3h3qu"
      },
      "source": [
        "O feature-map final tem forma (4, 4, 512). Esse é a fature onde colocaremos um classificador fully-connecteds.\n",
        "\n",
        "Aqui, podemos proceder de duas formas:\n",
        "\n",
        "1 - Executando a base convolucional sobre nosso conjunto de dados, gravando sua saída em um array Numpy no disco e, em seguida, usando esses dados como entrada para um classificador (fully-connecteds). \n",
        "\n",
        "Solução rápida porque requer a execução da base convolucional apenas uma vez para cada imagem de entrada. \n",
        "\n",
        "No entanto, essa técnica não nos permitiria aproveitar o data augmentation.\n",
        "\n",
        "2 - Estendendo o modelo que temos (conv_base) adicionando camadas Densas na parte superior e executando tudo de ponta a ponta nos dados de entrada.\n",
        "\n",
        "Vamos tentar a primeira opção:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5jiYBgpjmZB"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-TT0A0djnId"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('data/')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIzmWNBXjqMq"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "base_dir = 'data/cats_and_dogs_filtered/'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "# test_dir = os.path.join(base_dir, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIvurRM-jhfq"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 20\n",
        "\n",
        "def extract_features(directory, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "    i = 0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = conv_base.predict(inputs_batch)\n",
        "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "        i += 1\n",
        "        if i * batch_size >= sample_count:\n",
        "            # Note that since generators yield data indefinitely in a loop,\n",
        "            # we must `break` after every image has been seen once.\n",
        "            break\n",
        "    return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(train_dir, 2000)\n",
        "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
        "# test_features, test_labels = extract_features(test_dir, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixJwmJQrkNNC"
      },
      "source": [
        "As features extraídos são da forma (samples, 4, 4, 512). Vamos adicionar um classificador densamente conectado; portanto, primeiro devemos aplicar flatten para (samples, 8192):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF2s8HfFkZ2t"
      },
      "source": [
        "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
        "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
        "# test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbzwNHBMk48t"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_features, train_labels,\n",
        "                    epochs=30,\n",
        "                    batch_size=20,\n",
        "                    validation_data=(validation_features, validation_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpDbLSYtlb5U"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAusAhsgmpKC"
      },
      "source": [
        "Observe que a acurácia do modelo no conjunto de validação já foii melhor do que anteriormente (com data augmentation e sem usar a VGG16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Aluve_im3SV"
      },
      "source": [
        "*Obs.: Veja o notebook \"unidade03_keras_extract-features.ipynb\" antes de continuarmos*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k82F3Vy-nC37"
      },
      "source": [
        "A outra forma de fazer é (opção 2) estendendo o modelo que temos (conv_base) adicionando camadas Densas na parte superior e executando tudo de ponta a ponta nos dados de entrada. Muito mais lento (necessário o uso de GPU)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8br1Uwicnlzc"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH0x0EkInw5K"
      },
      "source": [
        "input_shape=(None, 150, 150, 3)\n",
        "model.build(input_shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwfwKk5Nn5LT"
      },
      "source": [
        "A base convolucional do VGG16 possui 14.714.688 parâmetros, o que é muito grande. O classificador que estamos adicionando no topo tem 2 milhões de parâmetros.\n",
        "\n",
        "Antes de compilar e treinar nosso modelo, uma coisa muito importante a fazer é \"freeze\" a base convolucional (VGG16). \"Freezing\" uma camada ou conjunto de camadas significa impedir que seus pesos sejam atualizados durante o treinamento. \n",
        "\n",
        "Se não fizer isso, as representações aprendidas anteriormente pela base convolucional (VGG16) serão modificadas durante o treinamento. Como as camadas densas na parte superior são inicializadas aleatoriamente, atualizações dos pesos seriam propagadas pela rede, destruindo o modelo pré-treinado.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQbXKk0Vox5W"
      },
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iORTioJo13i"
      },
      "source": [
        "# Freezing a base convolucional\n",
        "conv_base.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZXB6yHqo9R9"
      },
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bLlDwDNpC__"
      },
      "source": [
        "Com essa configuração, apenas os pesos das duas camadas Densas que adicionamos serão treinados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpzNBwDKpR8I"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to 150x150\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwFprN-QpY-v"
      },
      "source": [
        "model.save('cats_and_dogs_small_3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGsNhmvspadO"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvsU5p9GpiS1"
      },
      "source": [
        "**Fine-tuning**\n",
        "\n",
        "Consiste em descongelar algumas das camadas superiores de uma base de modelo congelada usada para extração de features e treinar em conjunto a parte recém-adicionada do modelo (no nosso caso, o classificador) e essas camadas superiores. \n",
        "\n",
        "Isso ajusta levemente as representações mais abstratas do modelo que está sendo reutilizado, a fim de torná-las mais relevantes para o problema em questão."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuN77GhPp8tg"
      },
      "source": [
        "Congelamos a base convolucional da VGG16 para poder treinar um classificador inicializado aleatoriamente no topo. \n",
        "\n",
        "Pelo mesmo motivo, só é possível ajustar as camadas superiores da base convolucional depois que o classificador na parte superior já tiver sido treinado. \n",
        "\n",
        "Portanto, as etapas para o fine-tuning de uma rede são as seguintes:\n",
        "\n",
        "1) Adicione sua rede personalizada (a nossa rede) em cima de uma rede básica já treinada (VGG16).\n",
        "2) Congele a rede base (VGG16).\n",
        "3) Treine a parte que adicionada (o que acabamos de fazer).\n",
        "4) Descongele algumas camadas na rede base (da VGG16).\n",
        "5) Treine em conjunto essas duas camadas (VGG16 com algumas camadas descongeladas mais o nosso modelo de classificação).\n",
        "\n",
        "Vamos descongelar nossa conv_base e congelaremos camadas individuais dentro dela."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3YjEaAPq9Wz"
      },
      "source": [
        "Ajustaremos as três últimas camadas convolucionais, o que significa que todas as camadas até block4_pool (veja a VGG original abaixo) devem ser congeladas e as camadas block5_conv1, block5_conv2 e block5_conv3 devem ser treináveis.\n",
        "\n",
        "Optamos por apenas ajudar as últimas camadas e não as primeiras porque estas últimas aprendem representação mais específicas (para o nosso caso, preferimos as representações mais genéricas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9o1IfPxrFb8"
      },
      "source": [
        "# VGG16 original (base convolucional)\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dcvy0a_MrnnY"
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Vm9eCNsAdn"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      # epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19tIS8NWsUbj"
      },
      "source": [
        "model.save('cats_and_dogs_small_4.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz-SI9AKsVXr"
      },
      "source": [
        "def smooth_curve(points, factor=0.8):\n",
        "  smoothed_points = []\n",
        "  for point in points:\n",
        "    if smoothed_points:\n",
        "      previous = smoothed_points[-1]\n",
        "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "    else:\n",
        "      smoothed_points.append(point)\n",
        "  return smoothed_points\n",
        "\n",
        "plt.plot(epochs,\n",
        "         smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
        "plt.plot(epochs,\n",
        "         smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs,\n",
        "         smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
        "plt.plot(epochs,\n",
        "         smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLmtmr5PsxAc"
      },
      "source": [
        "Se você tiver um conjunto de teste, utile-o para testar o modelo  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkNlCIITs4b2"
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('test acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWtLrCEitVp9"
      },
      "source": [
        "Referência: François Chollet. Deep Learning with Python. November 2017"
      ]
    }
  ]
}