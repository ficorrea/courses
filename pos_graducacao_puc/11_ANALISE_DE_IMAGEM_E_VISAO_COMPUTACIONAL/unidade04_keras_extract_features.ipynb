{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unidade03_keras_extract-features.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htohdAMEKbG5"
      },
      "source": [
        "**Using a pre-trained convnet to feature extraction**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iPfUK1ULkpM"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe_qxqZeMZsM"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('data/')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG2pSHUVKhDN"
      },
      "source": [
        "import tensorflow.keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-jtGdf6I8em"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(150, 150, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuCwTfQbKkv7"
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-oCWzYGKnek"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "base_dir = 'data/cats_and_dogs_filtered/'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "# test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 20\n",
        "\n",
        "def extract_features(directory, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "    i = 0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = conv_base.predict(inputs_batch)\n",
        "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "        i += 1\n",
        "        if i * batch_size >= sample_count:\n",
        "            # Note that since generators yield data indefinitely in a loop,\n",
        "            # we must `break` after every image has been seen once.\n",
        "            break\n",
        "    return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(train_dir, 2000)\n",
        "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
        "# test_features, test_labels = extract_features(test_dir, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViuVVZiALI2y"
      },
      "source": [
        "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
        "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
        "# test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVZWHIiaWo3p"
      },
      "source": [
        "print (train_features.shape)\n",
        "print (train_features[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTEPQ_QGiD6k"
      },
      "source": [
        "dist = np.sqrt(np.sum(np.square(np.subtract(train_features[18], train_features[24]))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_wEOP0pijXE"
      },
      "source": [
        "print (dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfJb36VueWgP"
      },
      "source": [
        "Referência: François Chollet. Deep Learning with Python. November 2017  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knYP4h6CAdQP"
      },
      "source": [
        "**Mais um exemplo (uma imagem por vez)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0EcSw5GAh1w"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "path1 = os.path.join(base_dir, 'validation/dogs/dog.2010.jpg')\n",
        "img1 = cv2.imread(path1) \n",
        "cv2_imshow(img1)\n",
        "\n",
        "\n",
        "path2 = os.path.join(base_dir, 'validation/dogs/dog.2011.jpg')\n",
        "img2 = cv2.imread(path2) \n",
        "cv2_imshow(img2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR6AZ2zCAlV6"
      },
      "source": [
        "print(img1.shape)\n",
        "print(img2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN4TuDCHAo_4"
      },
      "source": [
        "Vamos carregar a imagem usando PIL (biblioteca para processamento de imagens em Python)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMXqNMy6ApXD"
      },
      "source": [
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from PIL import Image\n",
        "\n",
        "img1 = load_img(path1, target_size=(150, 150))\n",
        "img2 = load_img(path2, target_size=(150, 150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n-CfVwWAtAU"
      },
      "source": [
        "Rescale de cada pixels de (0 a 255) para [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAJER6JNAsFW"
      },
      "source": [
        "from numpy import asarray\n",
        "\n",
        "## img1\n",
        "\n",
        "img1 = asarray(img1)\n",
        "\n",
        "print('Data Type: %s' % img1.dtype)\n",
        "print('Min: %.3f, Max: %.3f' % (img1.min(), img1.max()))\n",
        "\n",
        "img1 = img1.astype('float32')\n",
        "img1 /= 255.0\n",
        "\n",
        "print('Min: %.3f, Max: %.3f' % (img1.min(), img1.max()))\n",
        "\n",
        "### img2\n",
        "\n",
        "img2 = asarray(img2)\n",
        "\n",
        "print('Data Type: %s' % img2.dtype)\n",
        "print('Min: %.3f, Max: %.3f' % (img2.min(), img2.max()))\n",
        "\n",
        "img2 = img2.astype('float32')\n",
        "img2 /= 255.0\n",
        "\n",
        "print('Min: %.3f, Max: %.3f' % (img2.min(), img2.max()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUYXTPHBAzEV"
      },
      "source": [
        "x = img_to_array(img1)  # this is a Numpy array with shape (3, 150, 150)\n",
        "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "y = img_to_array(img2)  # this is a Numpy array with shape (3, 150, 150)\n",
        "y = y.reshape((1,) + y.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6spAirwA0ru"
      },
      "source": [
        "features_x = conv_base.predict(x)\n",
        "features_y = conv_base.predict(y)\n",
        "\n",
        "print(features_x.shape)\n",
        "print(features_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pGeUlgHfS77"
      },
      "source": [
        "features_x = np.reshape(features_x, (1, 4 * 4 * 512))\n",
        "features_y = np.reshape(features_y, (1, 4 * 4 * 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jksg0G9ffVrT"
      },
      "source": [
        "print(features_x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKU0ycRMCHY0"
      },
      "source": [
        "dist = np.sqrt(np.sum(np.square(np.subtract(features_x, features_y))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-7nuZ2dCKiP"
      },
      "source": [
        "print(dist)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}