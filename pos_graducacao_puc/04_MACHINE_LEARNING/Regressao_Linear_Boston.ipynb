{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regressao Linear-Boston.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "gZrXosczhbAn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Regressão Linear, Ridge e Lasso\n",
        "\n",
        "\n",
        "Realiza uma análise comparativa entre a Regressão Linear, o Ridge e o Lasso no Boston Housing Dataset.\n",
        "\n",
        "Baseado no livro: Andreas C. Müller, Sarah Guido (2016)\n",
        "*Introduction to Machine Learning with Python: A Guide for Data Scientists 1st Edition*.\n",
        "\n",
        "\n",
        "Este notebook foi desenvolvido para o ambiente GOOGLE COLAB ([colab.research.google.com](https://colab.research.google.com)).\n",
        "\n",
        "Prof. Hugo de Paula\n",
        "\n",
        "-------------------------------------------------------------------------------\n",
        "\n",
        "### Base de dados: Boston Housing dataset\n",
        "\n",
        "http://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
        "\n",
        "506 registros\n",
        "\n",
        "14 atributos\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xvDWWf3Bg7Jv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "boston = load_boston()\n",
        "X = boston.data\n",
        "print(\"Numero de atributos original:\")\n",
        "print(X.shape)\n",
        "\n",
        "# O PolynomialFeaures() aumenta a dimensão dos dados produzindo novos atributos \n",
        "# que são combinações lineares dos dados originais.\n",
        "\n",
        "X = MinMaxScaler().fit_transform(boston.data)\n",
        "X = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)\n",
        "\n",
        "print(\"Polynomial Features (atributos redundantes):\")\n",
        "print(X.shape)\n",
        "y = boston.target\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ETJFi2qY0LvR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Regressão Linear\n",
        "\n",
        "\n",
        "Os passos para indução de um modelo são:\n",
        "\n",
        "1.   Instanciar o modelo: ``` LinearRegression()```\n",
        "2.   Treinar o modelo: ```fit()```\n",
        "\n",
        "O método ```score()``` retorna o coeficiente R^2 de predição.\n"
      ]
    },
    {
      "metadata": {
        "id": "R1vwYYqg0MWS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "lr = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "print(\"Regressão Linear (com atributos redundantes)\")\n",
        "print(\"Acurácia na base de treinamento: {:.2f}\".format(lr.score(X_train, y_train)))\n",
        "print(\"Acurácia na base de teste: {:.2f}\".format(lr.score(X_test, y_test)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3vlTLXyVhq3k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ridge (Regressão linear com regularização L2)\n",
        "\n",
        "Força uma redução do valor dos coeficientes, penalizando coeficientes grandes que não contribuem significativamente para a explicação da variância do sinal.\n",
        "\n",
        "A força da regularização é dada pelo atributo ```alpha```, com valor *default* igual a 1.\n"
      ]
    },
    {
      "metadata": {
        "id": "7-nqvNMOhtBk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ridge = Ridge().fit(X_train, y_train)\n",
        "print(\"Ridge alpha=1\")\n",
        "print(\"Acurácia na base de treinamento: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
        "print(\"Acurácia na base de teste: {:.2f}\".format(ridge.score(X_test, y_test)))\n",
        "\n",
        "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
        "print(\"Ridge alpha=10\")\n",
        "print(\"Acurácia na base de treinamento: {:.2f}\".format(ridge10.score(X_train, y_train)))\n",
        "print(\"Acurácia na base de teste: {:.2f}\".format(ridge10.score(X_test, y_test)))\n",
        "\n",
        "\n",
        "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
        "print(\"Ridge alpha=0.1\")\n",
        "print(\"Acurácia na base de treinamento: {:.2f}\".format(ridge01.score(X_train, y_train)))\n",
        "print(\"Acurácia na base de teste: {:.2f}\".format(ridge01.score(X_test, y_test)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yPOeRRg115-h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Comparação da Regressão linear e Ridge\n",
        "\n",
        "O gráfico exibe a magnitude dos coeficientes obtidos por cada método. Pode-se observar como a regularização afeta a magnitude dos coeficientes do Ridge como um todo, mas sem zerar coeficientes de uma forma geral."
      ]
    },
    {
      "metadata": {
        "id": "2cAlohxg18KF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(ridge.coef_, 's', label=\"Ridge alpha=1\")\n",
        "plt.plot(ridge10.coef_, '^', label=\"Ridge alpha=10\")\n",
        "plt.plot(ridge01.coef_, 'v', label=\"Ridge alpha=0.1\")\n",
        "plt.plot(lr.coef_, 'o', label=\"Regressão linear\")\n",
        "plt.xlabel(\"Coeficiente\")\n",
        "plt.ylabel(\"Magnitude\")\n",
        "plt.hlines(0, 0, len(lr.coef_))\n",
        "plt.ylim(-25, 25)\n",
        "plt.legend()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YM97-e-0hw97",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LASSO (Regressão linear com regularização L1)\n",
        "\n",
        "Força uma redução do valor dos coeficientes, podendo zerar diversos coeficientes cujos atributos não contribuem significativamente para a previsão. Muito utilizado no apoio à tarefa de seleção de atributos (*feature selection*).\n",
        "\n",
        "A força da regularização é dada pelo atributo ```alpha```, com valor *default* igual a 1. ```Alpha=0``` resulta na regressão linear tradicional.\n"
      ]
    },
    {
      "metadata": {
        "id": "7s_dXacHhyDd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lasso = Lasso().fit(X_train, y_train)\n",
        "print(\"Lasso alpha=1\")\n",
        "print(\"Acurácia na base de treinamento: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
        "print(\"Acurácia na base de teste: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
        "print(\"Número de atributos usados: {}\".format(np.sum(lasso.coef_ != 0)))\n",
        "\n",
        "\n",
        "lasso001 = Lasso(alpha=0.01, max_iter=100000).fit(X_train, y_train)\n",
        "print(\"Lasso alpha=.01\")\n",
        "print(\"Acurácia na base de treinamento: {:.2f}\".format(lasso001.score(X_train, y_train)))\n",
        "print(\"Acurácia na base de teste: {:.2f}\".format(lasso001.score(X_test, y_test)))\n",
        "print(\"Número de atributos usados: {}\".format(np.sum(lasso001.coef_ != 0)))\n",
        "\n",
        "\n",
        "lasso00001 = Lasso(alpha=0.0001, max_iter=100000).fit(X_train, y_train)\n",
        "print(\"Lasso alpha=.0001\")\n",
        "print(\"Acurácia na base de treinamento: {:.2f}\".format(lasso00001.score(X_train, y_train)))\n",
        "print(\"Acurácia na base de teste: {:.2f}\".format(lasso00001.score(X_test, y_test)))\n",
        "print(\"Número de atributos usados: {}\".format(np.sum(lasso00001.coef_ != 0)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LhVLCHdg3MPV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Comparação da LASSO e Ridge\n",
        "\n",
        "O gráfico exibe a magnitude dos coeficientes obtidos por cada método."
      ]
    },
    {
      "metadata": {
        "id": "1sMC_ZQj3Mxz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(lasso.coef_, 's', label=\"Lasso alpha=1\")\n",
        "plt.plot(lasso001.coef_, '^', label=\"Lasso alpha=0.01\")\n",
        "plt.plot(lasso00001.coef_, 'v', label=\"Lasso alpha=0.0001\")\n",
        "plt.plot(ridge01.coef_, 'o', label=\"Ridge alpha=0.1\")\n",
        "plt.legend(ncol=2, loc=(0, 1.05))\n",
        "plt.ylim(-25, 25)\n",
        "plt.xlabel(\"Coeficiente\")\n",
        "plt.ylabel(\"Magnitude\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}