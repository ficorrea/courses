# -*- coding: utf-8 -*-
"""Regras de associacao.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OUQTcoVi0nUT9LGpJd5Ttp7NP_G0uO0K

# Regras de associação.

Cálculos de itemsets frequentes com o algoritmo Apriori utilizando o pacote ```mlxt```.


Este notebook foi desenvolvido para o ambiente GOOGLE COLAB ([colab.research.google.com](https://colab.research.google.com)).

Prof. Hugo de Paula
"""

! pip install mlxtend
! pip install xlrd

"""## Regras de associação geradas a partir de itemsets frequentes

Fonte: https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/

No exemplo a seguir, foi criado um ```dataset```  transacional formado por uma "lista de listas", onde cada linha corresponde a um cesto de compras de um supermercado hipotético.

Nesta base, são considerados ```itemsets``` frequentes aqueles que possuírem suporte superior a 0.6.
"""

import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules

# Dataset transcional com cestos de compras

dataset = [['Leite', 'Cebola', 'Batata', 'Feijão', 'Ovos', 'Iogurte'],
           ['Arroz', 'Cebola', 'Batata', 'Feijão', 'Ovos', 'Iogurte'],
           ['Leite', 'Maçã', 'Feijão', 'Ovos'],
           ['Leite', 'Milho', 'Feijão', 'Iogurte'],
           ['Milho', 'Cebola', 'Feijão', 'Sorvete', 'Ovos']]

te = TransactionEncoder()
te_ary = te.fit(dataset).transform(dataset)
df = pd.DataFrame(te_ary, columns=te.columns_)
frequent_itemsets = apriori(df, min_support=0.6, use_colnames=True)

print(frequent_itemsets)

"""###Regras de associação

Gera regras de associação com confiança mínima de 0.7.
"""

association_rules(frequent_itemsets, metric="confidence", min_threshold=0.7)

"""Gera regras de associação com lift mínimo de 1.2. 

É importante lembrar que valores de lift inferiores a 1 significam que a regra não possui causalidade relevante e não aumentam o nosso poder de previsão.
"""

rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1.2)
print(rules)

rules["antecedent_len"] = rules["antecedents"].apply(lambda x: len(x))
print(rules)

"""Exibe apenas as regras com antecedentes de comprimento maior ou igual a 2 e com confiança superior a 0.75 e lift superior a 1.2."""

rules[ (rules['antecedent_len'] >= 2) &
       (rules['confidence'] > 0.75) &
       (rules['lift'] > 1.2) ]

"""Exibe apenas as regras cujos antecedentes são Feijão e Ovos."""

rules[rules['antecedents'] == {'Ovos', 'Feijão'}]

"""## Análise de cesta de compras em Python

Fonte:  Chris Moffitt (2017), Introduction to Market Basket Analysis in Python, http://pbpython.com/market-basket-analysis.html


Neste exemplo é utilizada a base de dados **Online Retail** da UCI, disponível em [archive.ics.uci.edu/ml/machine-learning-databases/00352/Online Retail.xlsx](http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx)
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules

df = pd.read_excel('http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx')
print(df.head())

print(df.describe())

"""### Preparação de dados


Comando ```strip()``` elimina espaços no início e fim da string.

Comando ```dropna()``` remove registros com valores faltantes (*missing values*) no campo ```InvoiceNo```.

Comando ```df[~df['InvoiceNo'].str.contains('C')]``` remove registros com ```InvoiceNo``` iniciados com a letra *'C'*, uma vez que esses campos correspondem a pedidos cancelados.
"""

df['Description'] = df['Description'].str.strip()
df.dropna(axis=0, subset=['InvoiceNo'], inplace=True)
df['InvoiceNo'] = df['InvoiceNo'].astype('str')
df = df[~df['InvoiceNo'].str.contains('C')]
print(df.describe())

"""Gera uma base de dados apenas com pedidos da França. É gerada uma tabela pivô em que cada coluna corresponde à um produto e cada linha corresponde ao somatório da quantidade comprada daquele produto em um determinado pedido."""

basket = (df[df['Country'] =="France"]
          .groupby(['InvoiceNo', 'Description'])['Quantity']
          .sum().unstack().reset_index().fillna(0)
          .set_index('InvoiceNo'))
print(basket.head())

"""Transforma as quantidades em 0 ou 1."""

def encode_units(x):
    if x <= 0:
        return 0
    if x >= 1:
        return 1

basket_sets = basket.applymap(encode_units)
basket_sets.drop('POSTAGE', inplace=True, axis=1)

print(basket_sets.head())

"""### Geração de ```itemsets``` frequentes e de regras de associação."""

frequent_itemsets = apriori(basket_sets, min_support=0.07, use_colnames=True)
print(frequent_itemsets)

rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1)
print("\nAlgumas regras de associação geradas:\n", rules.head())
print("\nDimensões da matriz de regras:", rules.shape)

"""### Exemplos de filtros sobre regras de associação"""

rules[ (rules['lift'] >= 6) &
       (rules['confidence'] >= 0.8) ]

basket['ALARM CLOCK BAKELIKE GREEN'].sum()

basket['ALARM CLOCK BAKELIKE RED'].sum()

"""### Análise de cesto de compras da Alemanha

Esse código é semelhante ao código utilizado para gerar as regras da França. O objetivo é mostrar como que o suporte mínimo e a confiança mínima podem variar de uma base para outra. Um país pode ter um perfil de compras mais homogêneo e gerar regras com suporte maior, enquanto outro país pode gerar regras com suporte menor.
"""

basket2 = (df[df['Country'] =="Germany"]
          .groupby(['InvoiceNo', 'Description'])['Quantity']
          .sum().unstack().reset_index().fillna(0)
          .set_index('InvoiceNo'))

basket_sets2 = basket2.applymap(encode_units)
basket_sets2.drop('POSTAGE', inplace=True, axis=1)
frequent_itemsets2 = apriori(basket_sets2, min_support=0.05, use_colnames=True)
rules2 = association_rules(frequent_itemsets2, metric="lift", min_threshold=1)

rules2[ (rules2['lift'] >= 4) &
        (rules2['confidence'] >= 0.5)]