{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Edit Metadata","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Atividade-Pratica-4.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"73h6p7Bmpba4"},"source":["# Atividade 04: Implementando uma Rede Convolucional por meio do TensorFlow\n","\n","Nesta atividade, você irá treinar uma rede convolucional para realizar classificação de imagens utilizando o TensorFlow, e irá testá-la utilizando o dataset CIFAR-10.\n","\n","Nesta atividade, o TensorFlow será examinado em **três diferentes níveis de abstração**, o que irá ajudá-lo a compreender melhor seu funcionamento e prepará-lo para utilizá-lo em outros projetos.\n","\n","Nesta atividade, você irá:\n","\n","- **preparar** o dataset CIFAR-10 para utilizar no treinamento com TensorFlow\n","- **trabalhar** diretamente sobre grafos de computação do TensorFlow (**Nível de Abstração 1 - Fundamentos do TensorFlow**)\n","- **utilizar** a API `tf.keras.Model` para se definir arquiteturas de redes neurais arbitrárias (**Nível de Abstração 2 - API Keras Model**)\n","- **utilizar** a API `tf.keras.Sequential` para se definir arquiteturas de redes *feed-forward* lineares de forma conveniente e **explorar** biblioteca de funções para construção de modelos mais flexíveis  (**Nível de Abstração 3 - API Keras Sequential + API Funcional**)\n","\n","Detalhes sobre `Keras` serão apresentados mais adiante nesse *notebook*.\n","\n","A tabela abaixo compara as abordagem mencionadas acima em relação ao grau de flexibilidade e de conveniência na implementação de grafos de computação:\n","\n","| API           | Flexibilidade | Conveniência |\n","|---------------|-------------|-------------|\n","| Fundamentos      | Alta        | Baixa         |\n","| `tf.keras.Model`     | Alta        | Média      |\n","| `tf.keras.Sequential` | Baixa         | Alta        |"]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"i8lJRrWIzQ-k"},"source":["## TensorFlow\n","TensorFlow é um sistema para execução de grafos de computação sobre *tensores*, com um suporte nativo para realização de propagação retrógrada (*backpropagation*). Nele, trabalha-se com *tensores* que representam vetores/matrizes n-dimensionais análogas aos `ndarray` encontrados em `numpy`.\n","\n","### Por que utilizar TensorFlow?\n","\n","* Seu código irá executar em GPUs! Assim o treinamento pode ser realizado de forma mais rápida. A escrita de código próprio para execução em GPUs pode ser muito trabalhosa e está além do escopo dessa disciplina (porém, o uso de TensorFlow viabiliza a utilização de GPUs de forma transparente).\n","* Utilizar com um `framework` como o TensorFlow permite que você produza código de forma mais eficiente e eficaz ao invés de implementar tudo no zero. \n","* TensorFlow representa um dos melhores `frameworks` para implementação de redes profundas \n","* Você ganhará familiaridade com o tipo de código utilizado em aprendizagem profunda tanto na academia como na indústria. "]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"PCeTEtLhzQ-l"},"source":["## Como você pode aprender e aprofundar em TensorFlow?\n","\n","TensorFlow possui muitos tutoriais disponíveis, incluindo aqueles do próprio pessoal da [Google](https://www.tensorflow.org/get_started/get_started).\n","\n","De toda forma, esse *notebook* irá guiá-lo sobre as etapas que você precisa realizar para treinar modelos no TensorFlow. No final desse *notebook*, você encontrará links para tutoriais auxiliares caso você deseje aprender mais ou necessite de esclarecimentos adicionais sobre tópicos que não sejam tratados de forma completa aqui.\n","\n","**NOTA: Este *notebook* deve ser utilizado com a versão `2.2.0-rc3` do TensorFlow. A maioria dos exemplos na Web atualmente ainda utilizam versões `1.x`, portanto tenha cuidado para não se confundir quando consultar a documentação**.\n","\n","## Instalando TensorFlow 2.0 (APENAS SE VOCÊ FOR TRABALHAR LOCALMENTE)\n","\n","1. Tenha a última versão de Anaconda instalada em sua máquina.\n","2. Crie uma novo ambiente `conda` a partir do `Python 3.7`. Aqui, chamamos esse ambiente de `tf_20_env`.\n","3. Execute o comando: `source activate tf_20_env`\n","4. Em seguida, use `pip` para instalar TensorFlow 2.0 conforme descrito em: https://www.tensorflow.org/install"]},{"cell_type":"markdown","metadata":{"id":"EPdPJRAizQ-m"},"source":["# Preparação\n","\n","Primeiramente, vamos carregar os dados do dataset CIFAR-10. \n","\n","Nas atividades anteriores, você utilizou código específico para baixar e ler o dataset CIFAR-10; contudo o pacote `tf.keras.datasets` no TensorFlow fornece funções utilitárias para carga de vários datasets comuns.\n","\n","Para o propósito dessa atividade, ainda será utilizado código para preprocessamento dos dados e iteração sobre eles em *minibatches*. O pacote `tf.data` no TensorFlow fornece ferramentas para automatizar esse processo, porém trabalhar com esse pacote está fora do escopo dessa atividade. Entretanto, o uso do pacote `tf.data` pode ser muito mais eficiente que a abordagem simples usada nesse *notebook* e você talvez deva considerar seu uso futuramente."]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"4_-Rl_rVzQ-n"},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","import math\n","import timeit\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"U6q5mAe9zQ-q"},"source":["def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n","    \"\"\"\n","    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n","    it for the two-layer neural net classifier. These are the same steps as\n","    we used for the SVM, but condensed to a single function.\n","    \"\"\"\n","    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n","    cifar10 = tf.keras.datasets.cifar10.load_data()\n","    (X_train, y_train), (X_test, y_test) = cifar10\n","    X_train = np.asarray(X_train, dtype=np.float32)\n","    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n","    X_test = np.asarray(X_test, dtype=np.float32)\n","    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n","\n","    # Subsample the data\n","    mask = range(num_training, num_training + num_validation)\n","    X_val = X_train[mask]\n","    y_val = y_train[mask]\n","    mask = range(num_training)\n","    X_train = X_train[mask]\n","    y_train = y_train[mask]\n","    mask = range(num_test)\n","    X_test = X_test[mask]\n","    y_test = y_test[mask]\n","\n","    # Normalize the data: subtract the mean pixel and divide by std\n","    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n","    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n","    X_train = (X_train - mean_pixel) / std_pixel\n","    X_val = (X_val - mean_pixel) / std_pixel\n","    X_test = (X_test - mean_pixel) / std_pixel\n","\n","    return X_train, y_train, X_val, y_val, X_test, y_test\n","\n","# If there are errors with SSL downloading involving self-signed certificates,\n","# it may be that your Python version was recently installed on the current machine.\n","# See: https://github.com/tensorflow/tensorflow/issues/10779\n","# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n","#   ...replacing paths as necessary.\n","\n","# Invoke the above function to get our data.\n","NHW = (0, 1, 2)\n","X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n","print('Train data shape: ', X_train.shape)\n","print('Train labels shape: ', y_train.shape, y_train.dtype)\n","print('Validation data shape: ', X_val.shape)\n","print('Validation labels shape: ', y_val.shape)\n","print('Test data shape: ', X_test.shape)\n","print('Test labels shape: ', y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"KY-d8-GuzQ-t"},"source":["class Dataset(object):\n","    def __init__(self, X, y, batch_size, shuffle=False):\n","        \"\"\"\n","        Construct a Dataset object to iterate over data X and labels y\n","        \n","        Inputs:\n","        - X: Numpy array of data, of any shape\n","        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n","        - batch_size: Integer giving number of elements per minibatch\n","        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n","        \"\"\"\n","        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n","        self.X, self.y = X, y\n","        self.batch_size, self.shuffle = batch_size, shuffle\n","\n","    def __iter__(self):\n","        N, B = self.X.shape[0], self.batch_size\n","        idxs = np.arange(N)\n","        if self.shuffle:\n","            np.random.shuffle(idxs)\n","        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n","\n","\n","train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n","val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n","test_dset = Dataset(X_test, y_test, batch_size=64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AD4pMsGazQ-w"},"source":["# We can iterate through a dataset like this:\n","for t, (x, y) in enumerate(train_dset):\n","    print(t, x.shape, y.shape)\n","    if t > 5: break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gmi2zkzLzQ-y"},"source":["Você pode opcionalmente **usar GPU bastando setar o *flag* abaixo `USE_GPU` para `True`**.\n","\n","## Usuários de Colab\n","\n","Caso vocês esteja utilizando o `Colab`, você precisa ativar manualmente o uso de GPU. Você pode fazer isso selecionando `Ambiente de execução -> Alterar tipo de ambiente de execução` (em inglês, `Runtime -> Change runtime type`) e escolhendo `GPU` em `Acelerador de hardware` (em inglês, `Hardware Accelerator`). Observe que você deverá reexecutar as células desde o ínicio (caso faça essa mudança) pois o ambiente será reiniciado uma vez que faça essa alteração."]},{"cell_type":"code","metadata":{"tags":["pdf-ignore-input"],"id":"xAnSyO27zQ-z"},"source":["# Set up some global variables\n","USE_GPU = True\n","\n","if USE_GPU:\n","    device = '/device:GPU:0'\n","else:\n","    device = '/cpu:0'\n","\n","# Constant to control how often we print when training models\n","print_every = 100\n","\n","print('Using device: ', device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"puhqvMrzzQ-2"},"source":["# Fundamentos do TensorFlow\n","TensorFlow possui várias APIs de alto nível que o tornam uma ferramenta conveniente para se definir e treinar redes neurais. Algumas dessas construções serão cobertas mais adiante neste *notebook*. Nesta seção, vai se iniciar pela construção de um modelo com as primitivas mais básicas do TensorFlow de forma a ajudá-lo a compreender melhor o que se passa por detrás das APIs de mais alto nível.\n","\n","**\"Fundamentos do Tensorflow\" são importantes para se compreender os blocos básicos do TensorFlow, porém muitos deles envolvem conceitos do TensorFlow 1.x.** Iremos trabalhar com módulos legados (*antigos*) como `tf.Variable`.\n","\n","Dessa forma, leia com atenção e tente compreender as diferenças entre os módulos TensorFlow legados (antigos - 1.x) e os novos (2.0).\n","\n","### Breve histórico sobre TensorFlow 1.x\n","\n","TensorFlow 1.x é basicamente um `framework` para se trabalhar com **grafos de computação estáticos**. Nós em um grafo de computação representam **tensores** que irão armazenar vetores n-dimensionais quando o grafo estiver em execução; arestas no grafo representam funções que irão operar sobre os tensores quando o grafo for executado de forma a realizar alguma computação.\n","\n","Antes do TensorFlow 2.0, era necessário se configurar o grafo em duas fases. Existem vários tutoriais que explicam esse processo de duas fases. O processo pode ser resumido da seguinte forma para o TensorFlow 1.x:\n","1. **Construir um grafo de computação que descreve a computação que se deseja realizar**. Esse estágio não realiza nenhuma computação; ele só cria uma representação simbólica da computação a ser realizada. Nesse estágio será(ão) geralmente definido(s) um ou mais `placeholder` que  representam as entradas do grafo de computação.\n","2. **Executar o gafo de computação várias vezes**. Cada vez que o grafo for executado (p.ex. para um passo do método de gradiente), deve-se especificar quais partes do grafo você deseja computar e fornecer um um dicionário `feed_dict` com valores concretos para cada entrada (`placeholder`) do grafo.\n","\n","### Novo paradigma no TensorFlow 2.0\n","Agora, com o TensorFlow 2.0, pode-se simplesmente adotar uma forma funcional mais similar os demais códigos escritos em `Python` (e, também, mas similar em espiríto a um outro *framework* muito poderoso denominado `PyTorch`). Você pode obter mais detalhes em https://www.tensorflow.org/guide/eager.\n","\n","A principal diferença entre as abordagens do TensorFlow 1.x e do TensorFlow 2.0 é que nesse último não se utiliza `tf.Session`, `tf.run`, `placeholder`, `feed_dict`. Para se obter informações adicionais sobre as diferenças entre as duas versões e como realizar a conversão entre elas, verifique o guia oficial de migração em https://www.tensorflow.org/alpha/guide/migration_guide\n","\n","Mais adiante, o foco será sobre essa nova e mais simples abordagem."]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"nOyw8AV9zQ-2"},"source":["### Função Flatten (achatamento)\n","\n","Uma função de achatamento (`flatten`) pode ser definida de forma a realizar uma reformatação (*reshape*) dos dados de uma imagem para uso em uma rede completamente conectada.\n","\n","No TensorFlow, dados para mapas de características convolucionais são geralmente armazenados em um tensor com dimensões N x H x W x C em que:\n","\n","- N é o número de amostras de dados (tamanho do *minibatch*)\n","- H é a altura (*height*) do mapa de característica\n","- W é a largura (*width*) do mapa de característica\n","- C é o número de canais do mapa de característica\n","\n","Essa é a forma correta de se representar dados quando se realiza algo como uma convolução 2D, que necessita de informação sobre a distribuição espacial das informações. Porém, quando se utiliza camadas afim completamente conectadas para se processar uma imagem, deseja-se que cada amostra (imagem) seja representada como um único vetor -- não é útil se separar os diferentes canais, linhas e colunas dos dados. Assim, utiliza-se a operação de achatamento (`flatten`) para colapsar os valores `H x W x C` em um único vetor.\n","\n","Vale observar que a chamada para `tf.reshape` possui como alvo o formato `(N, -1)` significando que a primeira dimensão será mantida e a demais colapsadas em uma única segunda dimensão.\n","\n","**NOTA**: TensorFlow e PyTorch diferem sobre o layout default de um tensor; TensorFlow usa N x H x W x C porém PyTorch usa N x C x H x W."]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"C8cZ7zemzQ-3"},"source":["def flatten(x):\n","    \"\"\"    \n","    Input:\n","    - TensorFlow Tensor of shape (N, D1, ..., DM)\n","    \n","    Output:\n","    - TensorFlow Tensor of shape (N, D1 * ... * DM)\n","    \"\"\"\n","    N = tf.shape(x)[0]\n","    return tf.reshape(x, (N, -1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["pdf-ignore-input"],"id":"KIAmUZJNzQ-6"},"source":["def test_flatten():\n","    # Construct concrete values of the input data x using numpy\n","    x_np = np.arange(24).reshape((2, 3, 4))\n","    print('x_np:\\n', x_np, '\\n')\n","    # Compute a concrete output value.\n","    x_flat_np = flatten(x_np)\n","    print('x_flat_np:\\n', x_flat_np, '\\n')\n","\n","test_flatten()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FcXDLMexzQ-8"},"source":["### Fundamentos do TensorFlow: Definindo uma Rede de Duas Camadas\n","Agora, iremos implementar a primeira rede neural com TensorFlow: uma rede complementamente conectada com duas camadas usando ReLU e sem nenhum viés (termo independente) sobre o dataset CIFAR10. Por enquanto, utilizaremos apenas operações de baixo nível para definir a rede; mais adiante serão utilizadas abstrações mais elaboradas fornecidas pelo `tf.keras` para simplificar o processo.\n","\n","O *forward pass* da rede será definido na função `two_layer_fc` que receberá tensores com as entradas e pesos da rede e retorna um tensor com os valores de *score*. \n","\n","Depois de definida a arquitetura de rede na função `two_layer_fc`, a implementação será testada checando-se as dimensões da saída.\n","\n","**É muito importante que você leia e compreenda a implemtação abaixo.**"]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"kJkBzE2OzQ-8"},"source":["def two_layer_fc(x, params):\n","    \"\"\"\n","    A fully-connected neural network; the architecture is:\n","    fully-connected layer -> ReLU -> fully connected layer.\n","    Note that we only need to define the forward pass here; TensorFlow will take\n","    care of computing the gradients for us.\n","    \n","    The input to the network will be a minibatch of data, of shape\n","    (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units,\n","    and the output layer will produce scores for C classes.\n","\n","    Inputs:\n","    - x: A TensorFlow Tensor of shape (N, d1, ..., dM) giving a minibatch of\n","      input data.\n","    - params: A list [w1, w2] of TensorFlow Tensors giving weights for the\n","      network, where w1 has shape (D, H) and w2 has shape (H, C).\n","    \n","    Returns:\n","    - scores: A TensorFlow Tensor of shape (N, C) giving classification scores\n","      for the input data x.\n","    \"\"\"\n","    w1, w2 = params                   # Unpack the parameters\n","    x = flatten(x)                    # Flatten the input; now x has shape (N, D)\n","    h = tf.nn.relu(tf.matmul(x, w1))  # Hidden layer: h has shape (N, H)\n","    scores = tf.matmul(h, w2)         # Compute scores of shape (N, C)\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["pdf-ignore-input"],"id":"majrh8adzQ-_"},"source":["def two_layer_fc_test():\n","    hidden_layer_size = 42\n","\n","    # Scoping our TF operations under a tf.device context manager \n","    # lets us tell TensorFlow where we want these Tensors to be\n","    # multiplied and/or operated on, e.g. on a CPU or a GPU.\n","    with tf.device(device):        \n","        x = tf.zeros((64, 32, 32, 3))\n","        w1 = tf.zeros((32 * 32 * 3, hidden_layer_size))\n","        w2 = tf.zeros((hidden_layer_size, 10))\n","\n","        # Call our two_layer_fc function for the forward pass of the network.\n","        scores = two_layer_fc(x, [w1, w2])\n","\n","    print(scores.shape)\n","\n","two_layer_fc_test()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iXTMai2ZzQ_B"},"source":["### Fundamentos do TensorFlow: Definindo uma Rede Convolucional (ConvNet) de Três Camadas\n","Agora você deve completar a implementação da função `three_layer_convnet` que realiza o *forward pass* de uma rede convolucional de três camadas. A rede deve possuir a seguinte arquitetura:\n","\n","1. Uma camada convolucional (com viés) com `channel_1` filtros, cada um deles com formato `KW1 x KH1`, e preenchimento (*zero-padding*) de tamanho 2\n","2. Não-linearidade ReLU\n","3. Uma camada convolucional (com viés) com `channel_2` filtros, cada um deles com formato `KW2 x KH2`, e preenchimento (*zero-padding*) de tamanho 1\n","4. Não-linearidade ReLU\n","5. Uma camada completamente conectada com viés, produzindo *scores* para `C` classes.\n","\n","**DICA 1**: Para convoluções veja: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/conv2d; tenha cuidado com o preenchimento (*padding*)!\n","\n","**DICA 2**: Para viés veja: https://www.tensorflow.org/performance/xla/broadcasting"]},{"cell_type":"code","metadata":{"id":"8Fx86L1jzQ_B"},"source":["def three_layer_convnet(x, params):\n","    \"\"\"\n","    A three-layer convolutional network with the architecture described above.\n","    \n","    Inputs:\n","    - x: A TensorFlow Tensor of shape (N, H, W, 3) giving a minibatch of images\n","    - params: A list of TensorFlow Tensors giving the weights and biases for the\n","      network; should contain the following:\n","      - conv_w1: TensorFlow Tensor of shape (KH1, KW1, 3, channel_1) giving\n","        weights for the first convolutional layer.\n","      - conv_b1: TensorFlow Tensor of shape (channel_1,) giving biases for the\n","        first convolutional layer.\n","      - conv_w2: TensorFlow Tensor of shape (KH2, KW2, channel_1, channel_2)\n","        giving weights for the second convolutional layer\n","      - conv_b2: TensorFlow Tensor of shape (channel_2,) giving biases for the\n","        second convolutional layer.\n","      - fc_w: TensorFlow Tensor giving weights for the fully-connected layer.\n","        Can you figure out what the shape should be?\n","      - fc_b: TensorFlow Tensor giving biases for the fully-connected layer.\n","        Can you figure out what the shape should be?\n","    \"\"\"\n","    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n","    scores = None\n","    ############################################################################\n","    # TODO: Implement the forward pass for the three-layer ConvNet.            #\n","    ############################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","    pass\n","\n","    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    ############################################################################\n","    #                              END OF YOUR CODE                            #\n","    ############################################################################\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kqerigvRzQ_F"},"source":["Após definir o *forward pass* para a ConvNet de três camadas acima, execute o código da próxima célula para testar sua implementação. Semelhante a rede de duas camadas, o grafo será executado sobre tensores contendo zeros, portanto você deve assegurar que a função não tenham problemas de execução e que produz uma saída no formato correto.\n","\n","Quando você executar essa função, `scores_np` deve ter dimensões `(64, 10)`."]},{"cell_type":"code","metadata":{"id":"barebones_output_shape","tags":["pdf-ignore-input"]},"source":["def three_layer_convnet_test():\n","    \n","    with tf.device(device):\n","        x = tf.zeros((64, 32, 32, 3))\n","        conv_w1 = tf.zeros((5, 5, 3, 6))\n","        conv_b1 = tf.zeros((6,))\n","        conv_w2 = tf.zeros((3, 3, 6, 9))\n","        conv_b2 = tf.zeros((9,))\n","        fc_w = tf.zeros((32 * 32 * 9, 10))\n","        fc_b = tf.zeros((10,))\n","        params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n","        scores = three_layer_convnet(x, params)\n","\n","    # Inputs to convolutional layers are 4-dimensional arrays with shape\n","    # [batch_size, height, width, channels]\n","    print('scores_np has shape: ', scores.shape)\n","\n","three_layer_convnet_test()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Al2zJsfzQ_I"},"source":["### Fundamentos do TensorFlow: Passo de Treinamento\n","\n","Agora definiremos a função `training_step` para realizar um único passo de treinamento. Isso exigirá 03 etapas básicas:\n","\n","1. Computar a perda\n","2. Computar o gradiente da perda em relação a todos os pesos da rede\n","3. Fazer um passo de atulização de pesos utilizando SGD (*stochastic gradient descent*).\n","\n","São necessárias algumas poucas funções do TensorFlow para se realizar isso:\n","- Para cálculo da perda por entropia cruzada, pode-se utilizar `tf.nn.sparse_softmax_cross_entropy_with_logits`: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits\n","\n","- Para se obter a média da perda para as amostras de dados do *minibatch*, pode-se usar `tf.reduce_mean`:\n","https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/reduce_mean\n","\n","- Para computar o gradiente da perda em relação aos pesos, pode-se usar `tf.GradientTape` (útil para execução rápida):  https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/GradientTape\n","\n","- Já a modificação doa valores de pesos armazenados em um tensor, pode-se usar `tf.assign_sub` (\"sub\" é para subtração): https://www.tensorflow.org/api_docs/python/tf/assign_sub \n"]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"gj4eFOCfzQ_I"},"source":["def training_step(model_fn, x, y, params, learning_rate):\n","    with tf.GradientTape() as tape:\n","        scores = model_fn(x, params) # Forward pass of the model\n","        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n","        total_loss = tf.reduce_mean(loss)\n","        grad_params = tape.gradient(total_loss, params)\n","\n","        # Make a vanilla gradient descent step on all of the model parameters\n","        # Manually update the weights using assign_sub()\n","        for w, grad_w in zip(params, grad_params):\n","            w.assign_sub(learning_rate * grad_w)\n","                        \n","        return total_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"U-gJW49uzQ_K"},"source":["def train_part2(model_fn, init_fn, learning_rate):\n","    \"\"\"\n","    Train a model on CIFAR-10.\n","    \n","    Inputs:\n","    - model_fn: A Python function that performs the forward pass of the model\n","      using TensorFlow; it should have the following signature:\n","      scores = model_fn(x, params) where x is a TensorFlow Tensor giving a\n","      minibatch of image data, params is a list of TensorFlow Tensors holding\n","      the model weights, and scores is a TensorFlow Tensor of shape (N, C)\n","      giving scores for all elements of x.\n","    - init_fn: A Python function that initializes the parameters of the model.\n","      It should have the signature params = init_fn() where params is a list\n","      of TensorFlow Tensors holding the (randomly initialized) weights of the\n","      model.\n","    - learning_rate: Python float giving the learning rate to use for SGD.\n","    \"\"\"\n","    \n","    \n","    params = init_fn()  # Initialize the model parameters            \n","        \n","    for t, (x_np, y_np) in enumerate(train_dset):\n","        # Run the graph on a batch of training data.\n","        loss = training_step(model_fn, x_np, y_np, params, learning_rate)\n","        \n","        # Periodically print the loss and check accuracy on the val set.\n","        if t % print_every == 0:\n","            print('Iteration %d, loss = %.4f' % (t, loss))\n","            check_accuracy(val_dset, x_np, model_fn, params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"F-s7lPbJzQ_N"},"source":["def check_accuracy(dset, x, model_fn, params):\n","    \"\"\"\n","    Check accuracy on a classification model, e.g. for validation.\n","    \n","    Inputs:\n","    - dset: A Dataset object against which to check accuracy\n","    - x: A TensorFlow placeholder Tensor where input images should be fed\n","    - model_fn: the Model we will be calling to make predictions on x\n","    - params: parameters for the model_fn to work with\n","      \n","    Returns: Nothing, but prints the accuracy of the model\n","    \"\"\"\n","    num_correct, num_samples = 0, 0\n","    for x_batch, y_batch in dset:\n","        scores_np = model_fn(x_batch, params).numpy()\n","        y_pred = scores_np.argmax(axis=1)\n","        num_samples += x_batch.shape[0]\n","        num_correct += (y_pred == y_batch).sum()\n","    acc = float(num_correct) / num_samples\n","    print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AiYGgKPRzQ_R"},"source":["### Fundamentos do TensorFlow: Inicialização\n","\n","Pode-se utilizar a seguinte função para se inicializar as matrizes de pesos utilizando o método de normalização de Kaiming (He et al. 2015)\n","\n","[1] He et al., *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*, ICCV 2015, https://arxiv.org/abs/1502.01852"]},{"cell_type":"code","metadata":{"id":"qr7k0N8qzQ_R"},"source":["def create_matrix_with_kaiming_normal(shape):\n","    if len(shape) == 2:\n","        fan_in, fan_out = shape[0], shape[1]\n","    elif len(shape) == 4:\n","        fan_in, fan_out = np.prod(shape[:3]), shape[3]\n","    return tf.keras.backend.random_normal(shape) * np.sqrt(2.0 / fan_in)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hMqE8Wr9zQ_V"},"source":["### Fundamentos do TensorFlow: Treinando uma Rede de Duas Camadas\n","\n","Agora, estamos prontos para utilizar todas as funções definidas acima no treinamento de uma rede de duas camadas completamente conectada sobre o dataset CIFAR-10.\n","\n","Basta então definir uma função para inicializar os pesos do modelo e chamar, em seguida, a função `train_part2`.\n","\n","Para se definir os pesos da rede é necessário se introduzir uma outra peça importante da API do TensorFLow: `tf.Variable`. \n","\n","Uma variável do TensorFlow é um tensor cujo valor é armazenado em um grafo e que persiste entre várias execuções do grafo de computação; entretanto diferente de constantes definidas com `tf.zeros` ou `tf.random_normal`, os valores de uma variável podem mudar na medida que o grafo executa; essas alterações irão persistir entre diferentes execuções do gafo. Assim, parâmetros da rede que são aprendidos são geralmente armazenados em variáveis.\n","\n","Você não precisa ajustar nenhum hiperparâmetro, mas (mesmo assim) deve alcançar uma acurácia de validação acima de 40% após uma época de treinamento."]},{"cell_type":"code","metadata":{"id":"YiUdiMNTzQ_W"},"source":["def two_layer_fc_init():\n","    \"\"\"\n","    Initialize the weights of a two-layer network, for use with the\n","    two_layer_network function defined above. \n","    You can use the `create_matrix_with_kaiming_normal` helper!\n","    \n","    Inputs: None\n","    \n","    Returns: A list of:\n","    - w1: TensorFlow tf.Variable giving the weights for the first layer\n","    - w2: TensorFlow tf.Variable giving the weights for the second layer\n","    \"\"\"\n","    hidden_layer_size = 4000\n","    w1 = tf.Variable(create_matrix_with_kaiming_normal((3 * 32 * 32, 4000)))\n","    w2 = tf.Variable(create_matrix_with_kaiming_normal((4000, 10)))\n","    return [w1, w2]\n","\n","learning_rate = 1e-2\n","train_part2(two_layer_fc, two_layer_fc_init, learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C1ly58u0zQ_Y"},"source":["### Fundamentos do TensorFlow: Treinando uma ConvNet de Três Camadas\n","\n","Agora, você deve usar o TensorFlow para treinar uma ConvNet de 3 camadas sobre o dataset CIFAR-10.\n","\n","Você deve implementar a função `three_layer_convnet_init`. Lembre-se de que a arquitetura da rede é a seguinte:\n","\n","1. Camada convolucional (com viés) com 32 filtros 5x5, e com preenchimento (*zero-padding*) de tamanho 2\n","2. Não-linearidade ReLU\n","3. Camada convolucional (com viés) com 16 filtros 3x3, e com preenchimento (*zero-padding*) de tamanho 1\n","4. Não-linearidade ReLU\n","5. Camada completamente conectada (com viés) para computar *scores* para 10 classes\n","\n","Você não precisa ajustar nenhum hiperparâmetro, mas (mesmo assim) deve alcançar uma acurácia de validação acima de 43% após uma época de treinamento."]},{"cell_type":"code","metadata":{"id":"barebones_accuracy"},"source":["def three_layer_convnet_init():\n","    \"\"\"\n","    Initialize the weights of a Three-Layer ConvNet, for use with the\n","    three_layer_convnet function defined above.\n","    You can use the `create_matrix_with_kaiming_normal` helper!\n","    \n","    Inputs: None\n","    \n","    Returns a list containing:\n","    - conv_w1: TensorFlow tf.Variable giving weights for the first conv layer\n","    - conv_b1: TensorFlow tf.Variable giving biases for the first conv layer\n","    - conv_w2: TensorFlow tf.Variable giving weights for the second conv layer\n","    - conv_b2: TensorFlow tf.Variable giving biases for the second conv layer\n","    - fc_w: TensorFlow tf.Variable giving weights for the fully-connected layer\n","    - fc_b: TensorFlow tf.Variable giving biases for the fully-connected layer\n","    \"\"\"\n","    params = None\n","    ############################################################################\n","    # TODO: Initialize the parameters of the three-layer network.              #\n","    ############################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","    pass\n","\n","    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    ############################################################################\n","    #                             END OF YOUR CODE                             #\n","    ############################################################################\n","    return params\n","\n","learning_rate = 3e-3\n","train_part2(three_layer_convnet, three_layer_convnet_init, learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"w1IxkvmNzQ_a"},"source":["# API Keras Model\n","\n","Implementar uma rede neural utilizando a API de baixo nível do TensorFlow é uma boa forma de entender como o TensorFlow funciona, porém é um pouco inconveniente, pois se deve manualmente manter e acompanhar todos os tensores armazenando parâmetros que serão aprendidos. Isso é simples para uma rede pequena, mas pode rapidamente se tornar impraticável para modelos grandes e complexos.\n","\n","Felizmente, o TensorFlow 2.0 fornece APIs de alto nível como `tf.keras` que facilitam a construção de modelos a partir de camadas modulares. Além disso, o TensorFlow 2.0 utilizar a execução rápida que avalia operações de forma imediata sem a necessidade de construção explíta de nenhum grafo de computação. Isso torna mais fácil de se escrever e depurar modelos.\n","\n","Nessa parte desse *notebook*, você irá definir um modelo de rede neural usando a API `tf.keras.Model`. Para implementar seu próprio modelo, você precisará do seguinte:\n","\n","1. Definir uma nova classe que seja herdeira de `tf.keras.Model`. Você deve dar um nome intuitivo a sua classe que sirva para descrevê-la, como `TwoLayerFC` ou `ThreeLayerConvNet`.\n","2. No método de inicialização `__init__()` para sua nova classe, você deve definir todas as camadas como atributos de classe. O pacote `tf.keras.layers` fornece muitas camadas comuns as redes neurais, como `tf.keras.layers.Dense` para camadas completamente conectadas e `tf.keras.layers.Conv2D` para camadas convolucionais. Internamente, essas camadas irão construir variáveis (tensores) para quaisquer parâmetros que devam ser aprendidos. **AVISO: Não se esqueça de chamar `super(YourModelName, self).__init__()` como a primeira instrução de seu inicializador!**\n","3. Implementar o método `call()` para sua classe, que será responsável pelo cálculo do *forward pass* de seu modelo, e estabelece a *conectividade* entre os elementos de sua rede. Camadas definidas em no método `__init__()` são utilizadas para implementar o método `__call__()`. Assim, as camadas podem seu usadas para transformar tensores de entrada em tensores de saída. Não define nenhuma nova camada no método `call()`; qualquer camada que você deseje utilizar no *forward pass* deve ser definida no método `__init__()`.\n","\n","Após definir sua subclasse de `tf.keras.Model`, você pode criar uma instância dela utilizá-la como um modelo.\n","\n","### Exemplo de Subclasse de Keras Model: Rede de Duas Camadas\n","\n","Eis agora um exemplo concreto de uso da API `tf.keras.Model` para se definir uma rede de duas camadas. Existem alguns pequenos pontos da API a se prestar atenção aqui:\n","\n","Será utilizado um objeto `Initializer` para definir valores iniciais para os parâmetros/pesos (a serem aprendidos) nas camadas; em particular `tf.initializers.VarianceScaling` fornece um comportamento similar ao método de inicialização de Kaiming utilizado anteriormente nesse *notebook* (ver He et al. 2015). Você pode encontrar mais detalhes em https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/initializers/VarianceScaling\n","\n","Serão utilizado objetos `tf.keras.layers.Dense`para representar as duas camadas completamente conectadas do modelo. Além de multiplicar suas entradas por uma matriz de pesos e adicionar um vetor de viés, essas camadas também podem aplicar uma não-linearidade para você. Para a primeira camada, especifica-se um função de ativação ReLU passando o parâmetro `activation='relu'` para o construtor; já a segunda camada usa uma função de ativação *softmax*. Por fim, utiliza-se `tf.keras.layers.Flatten` para achatar o tensor de entrada antes das camadas completamente conectadas."]},{"cell_type":"code","metadata":{"tags":["pdf-ignore-input"],"id":"wt7PWXtjzQ_b"},"source":["class TwoLayerFC(tf.keras.Model):\n","    def __init__(self, hidden_size, num_classes):\n","        super(TwoLayerFC, self).__init__()        \n","        initializer = tf.initializers.VarianceScaling(scale=2.0)\n","        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n","                                   kernel_initializer=initializer)\n","        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n","                                   kernel_initializer=initializer)\n","        self.flatten = tf.keras.layers.Flatten()\n","    \n","    def call(self, x, training=False):\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        return x\n","\n","\n","def test_TwoLayerFC():\n","    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n","    input_size, hidden_size, num_classes = 50, 42, 10\n","    x = tf.zeros((64, input_size))\n","    model = TwoLayerFC(hidden_size, num_classes)\n","    with tf.device(device):\n","        scores = model(x)\n","        print(scores.shape)\n","        \n","test_TwoLayerFC()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aUZzlSbvzQ_d"},"source":["### Uso da API Keras Model: Definindo uma ConvNet de Três Camadas\n","\n","Agora, você deve implementar uma ConvNet de 3 camadas usando a API `tf.keras.Model`. Seu modelo deve a mesma arquitetura utilizada anteriormente neste *notebook*:\n","\n","1. Camada convolucional com filtros 5x5 e com preenchimento (*zero-padding*) de tamanho 2\n","2. Não-linearidade ReLU\n","3. Camada convolucional com filtros 3x3 e com preenchimento (*zero-padding*) de tamanho 1\n","4. Não-linearidade ReLU\n","5. Camada completamente conectada (com viés) para computar *scores* para classes\n","6. Não-linearidade Softmax\n","\n","Você deve inicializar os pesos de sua rede utilizando o mesmo método usado na rede de duas camada acima.\n","\n","**DICA**: Para conseguir implementar, explore a documentação de `tf.keras.layers.Conv2D` e `tf.keras.layers.Dense`:\n","\n","https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n","\n","https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"]},{"cell_type":"code","metadata":{"id":"S9cBMCvazQ_d"},"source":["class ThreeLayerConvNet(tf.keras.Model):\n","    def __init__(self, channel_1, channel_2, num_classes):\n","        super(ThreeLayerConvNet, self).__init__()\n","        ########################################################################\n","        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n","        # should instantiate layer objects to be used in the forward pass.     #\n","        ########################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","        pass\n","\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ########################################################################\n","        #                           END OF YOUR CODE                           #\n","        ########################################################################\n","        \n","    def call(self, x, training=False):\n","        scores = None\n","        ########################################################################\n","        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n","        # should use the layer objects defined in the __init__ method.         #\n","        ########################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","        pass\n","\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ########################################################################\n","        #                           END OF YOUR CODE                           #\n","        ########################################################################        \n","        return scores"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"INM14tQSzQ_f"},"source":["Uma vez que você termine a implementaçaõ da classe `ThreeLayerConvNet` acima, você pode executar o seguinte código para assegurar que sua implementação não contém de execução e que produz saída no formato esperado."]},{"cell_type":"code","metadata":{"id":"keras_model_output_shape"},"source":["def test_ThreeLayerConvNet():    \n","    channel_1, channel_2, num_classes = 12, 8, 10\n","    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n","    with tf.device(device):\n","        x = tf.zeros((64, 3, 32, 32))\n","        scores = model(x)\n","        print(scores.shape)\n","\n","test_ThreeLayerConvNet()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hS1EaZ8BzQ_h"},"source":["### Uso da API Keras Model: Treinamento Rápido\n","\n","Apesar de moelos em Keras possuirem um método de treinamento embutido (por meio de `model.fit`), as vezes é necessário se *customizar* o treinamento. A seguir, vocÊ verá um exemplo de um método de treinamento implementado por meio de execução rápida.\n","\n","Em particular, observe o uso de `tf.GradientTape`. Diferenciação automática é utilizada para implementar a propagação retrógrada em `frameworks` como o TensorFlow. Durante a execução rápida, `tf.GradientTape` é usado para cálculo de gadientes. \n","\n","Além disso, TensorFlow 2.0 possui um mecanismo simplificadopara avaliação de métricas por meio do módulo `tf.keras.metrics`. Cada métrica é um objeto. Pode-se adicionar observações por meio de `update_state()` e eliminar todas elas usando `reset_state()`. Para se obter o valor corrente de uma métrica, usa-se o método `result()` sobre o respectivo objeto. "]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"jmmkBcBczQ_i"},"source":["def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n","    \"\"\"\n","    Simple training loop for use with models defined using tf.keras. It trains\n","    a model for one epoch on the CIFAR-10 training set and periodically checks\n","    accuracy on the CIFAR-10 validation set.\n","    \n","    Inputs:\n","    - model_init_fn: A function that takes no parameters; when called it\n","      constructs the model we want to train: model = model_init_fn()\n","    - optimizer_init_fn: A function which takes no parameters; when called it\n","      constructs the Optimizer object we will use to optimize the model:\n","      optimizer = optimizer_init_fn()\n","    - num_epochs: The number of epochs to train for\n","    \n","    Returns: Nothing, but prints progress during trainingn\n","    \"\"\"    \n","    with tf.device(device):\n","\n","        # Compute the loss like we did in Part II\n","        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","        \n","        model = model_init_fn()\n","        optimizer = optimizer_init_fn()\n","        \n","        train_loss = tf.keras.metrics.Mean(name='train_loss')\n","        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","    \n","        val_loss = tf.keras.metrics.Mean(name='val_loss')\n","        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n","        \n","        t = 0\n","        for epoch in range(num_epochs):\n","            \n","            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n","            train_loss.reset_states()\n","            train_accuracy.reset_states()\n","            \n","            for x_np, y_np in train_dset:\n","                with tf.GradientTape() as tape:\n","                    \n","                    # Use the model function to build the forward pass.\n","                    scores = model(x_np, training=is_training)\n","                    loss = loss_fn(y_np, scores)\n","      \n","                    gradients = tape.gradient(loss, model.trainable_variables)\n","                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","                    \n","                    # Update the metrics\n","                    train_loss.update_state(loss)\n","                    train_accuracy.update_state(y_np, scores)\n","                    \n","                    if t % print_every == 0:\n","                        val_loss.reset_states()\n","                        val_accuracy.reset_states()\n","                        for test_x, test_y in val_dset:\n","                            # During validation at end of epoch, training set to False\n","                            prediction = model(test_x, training=False)\n","                            t_loss = loss_fn(test_y, prediction)\n","\n","                            val_loss.update_state(t_loss)\n","                            val_accuracy.update_state(test_y, prediction)\n","                        \n","                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n","                        print (template.format(t, epoch+1,\n","                                             train_loss.result(),\n","                                             train_accuracy.result()*100,\n","                                             val_loss.result(),\n","                                             val_accuracy.result()*100))\n","                    t += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O42Gyk12zQ_k"},"source":["### Uso da API Keras Model: Treinando uma Rede de Duas Camadas\n","\n","Agora, pode-se utilizar as ferramentar definidas anteriormente para se treinar uma rede de duas camadas sobre o dataset CIFAR-10. \n","\n","Definiu-se os métodos `model_init_fn` e `optimizer_init_fn` que controem o modelo e executam a otimização do mesmo, respectivamente. \n","\n","Deseja-se treinar o modelo por meio do SGD (*stochastic gradient descent*) sem uso de momento, portanto, utiliza-se a função `tf.keras.optimizers.SGD`; você pode [ler mais a esse respeito aqui](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD).\n","\n","Você não precisa ajustar nenhum hiperparâmetro, mas (mesmo assim) deve alcançar uma acurácia de validação acima de 40% após uma época de treinamento."]},{"cell_type":"code","metadata":{"id":"RDsrltTIzQ_k"},"source":["hidden_size, num_classes = 4000, 10\n","learning_rate = 1e-2\n","\n","def model_init_fn():\n","    return TwoLayerFC(hidden_size, num_classes)\n","\n","def optimizer_init_fn():\n","    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n","\n","train_part34(model_init_fn, optimizer_init_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rLcWSbkwzQ_n"},"source":["### Uso da API Keras Model: Treinando uma ConvNet de Três Camadas\n","\n","Agora você deve utilizar as ferramentas definidas anteriormente para treinar uma ConvNet de 3 camadas sobre o dataset CIFAR-10. Sua ConvNet deve possuir 32 filtros na primeira camada convolucional e 16 filtros na segunda camada.\n","\n","Para treinar o modelo, você deve adotar o método do gradiente com o momento de Nesterov de 0,9.  \n","\n","**DICA**: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n","\n","Você não precisa ajustar nenhum hiperparâmetro, mas (mesmo assim) deve alcançar uma acurácia de validação acima de 50% após uma época de treinamento."]},{"cell_type":"code","metadata":{"id":"keras_model_accuracy"},"source":["learning_rate = 3e-3\n","channel_1, channel_2, num_classes = 32, 16, 10\n","\n","def model_init_fn():\n","    model = None\n","    ############################################################################\n","    # TODO: Complete the implementation of model_fn.                           #\n","    ############################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","    pass\n","\n","    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    ############################################################################\n","    #                           END OF YOUR CODE                               #\n","    ############################################################################\n","    return model\n","\n","def optimizer_init_fn():\n","    optimizer = None\n","    ############################################################################\n","    # TODO: Complete the implementation of model_fn.                           #\n","    ############################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","    pass\n","\n","    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    ############################################################################\n","    #                           END OF YOUR CODE                               #\n","    ############################################################################\n","    return optimizer\n","\n","train_part34(model_init_fn, optimizer_init_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9EHF2BUKzQ_p"},"source":["# API Keras Sequential\n","\n","As implementações com a API `tf.keras.Model` permitem que você defina  modelos com qualquer número de camadas e com uma conectividade arbitrária entre elas.\n","\n","Contudo, para muitos modelos você não necessita de tamanha flexibilidade - grande parte dos modelos pode ser expressa como uma pilha sequencial de camadas em que a saída de uma camada é usada como entrada da próxima.\n","Caso seu modelo se encaixe nesse padrão, então existe um forma ainda mais fácil de se definir o modelo por meio do uso da API `tf.keras.Sequential`. Você não precisa escrever nenhuma classe customizada; basta chamar o construtor `tf.keras.Sequential` com uma lista contendo a senquência de camadas.\n","\n","Uma dificuldade no uso de `tf.keras.Sequential` é que você deve definir as dimensões da entrada do modelo e informar isso (por meio do valor de `input_shape`) à primeira camada de seu modelo.\n","\n","### Uso da API Keras Sequential: Rede de Duas Camadas\n","\n","Agora, a rede completamente conectada de duas camadas será reescrita usando `tf.keras.Sequential`, e treinada com o método definido acima.\n","\n","Você não precisa ajustar nenhum hiperparâmetro, mas (mesmo assim) deve alcançar uma acurácia de validação acima de 40% após uma época de treinamento."]},{"cell_type":"code","metadata":{"id":"s1i3FzxfzQ_q"},"source":["learning_rate = 1e-2\n","\n","def model_init_fn():\n","    input_shape = (32, 32, 3)\n","    hidden_layer_size, num_classes = 4000, 10\n","    initializer = tf.initializers.VarianceScaling(scale=2.0)\n","    layers = [\n","        tf.keras.layers.Flatten(input_shape=input_shape),\n","        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n","                              kernel_initializer=initializer),\n","        tf.keras.layers.Dense(num_classes, activation='softmax', \n","                              kernel_initializer=initializer),\n","    ]\n","    model = tf.keras.Sequential(layers)\n","    return model\n","\n","def optimizer_init_fn():\n","    return tf.keras.optimizers.SGD(learning_rate=learning_rate) \n","\n","train_part34(model_init_fn, optimizer_init_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZtmDy6HCzQ_s"},"source":["### Abstraindo o Método de Treinamento\n","\n","Nos exemplos anteriores, foi utilizado um método de treinamento customizado para se treinar os modelos (p.ex. `train_part34`). Excrever seu próprio método de treinamento só é necessário se você desejar mais flexibilidade e controle durante o treinamento de seu modelo. Alternativamente, você pode utilizar de métodos prontos da API como `tf.keras.Model.fit()` e `tf.keras.Model.evaluate` para treinar e avaliar um modelo. Nesse caso, você deve lembrar de configurar antes seu modelo para treinamento chamando `tf.keras.Model.compile`.\n","\n","Você não precisa ajustar nenhum hiperparâmetro, mas (mesmo assim) deve alcançar uma acurácia de validação acima de 42% após uma época de treinamento."]},{"cell_type":"code","metadata":{"id":"Wak9IfnjzQ_s"},"source":["model = model_init_fn()\n","model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n","              loss='sparse_categorical_crossentropy',\n","              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n","model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n","model.evaluate(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QG8cXNHszQ_u"},"source":["### Uso da API Keras Sequential: ConvNet de Três Camadas\n","\n","Agora você deve usar `tf.keras.Sequential` para reimplementar a  arquitetura da ConvNet de 3 camadas anterior. Como lembrete, seu modelo deve possuir a seguinte arquitetura:\n","\n","1. Camada convolucional com filtros 5x5 e com preenchimento (*zero-padding*) de tamanho 2\n","2. Não-linearidade ReLU\n","3. Camada convolucional com filtros 3x3 e com preenchimento (*zero-padding*) de tamanho 1\n","4. Não-linearidade ReLU\n","5. Camada completamente conectada (com viés) para computar *scores* para classes\n","6. Não-linearidade Softmax\n","\n","Você deve inicializar os pesos do modelo usando `tf.initializers.VarianceScaling` como antes e o modelo deve ser treinado com \n","momento de Nesterov de 0,9.\n","\n","Você não precisa ajustar nenhum hiperparâmetro, mas (mesmo assim) deve alcançar uma acurácia de validação acima de 45% após uma época de treinamento."]},{"cell_type":"code","metadata":{"id":"keras_sequential_accuracy"},"source":["def model_init_fn():\n","    model = None\n","    ############################################################################\n","    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n","    ############################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","    pass\n","\n","    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    ############################################################################\n","    #                            END OF YOUR CODE                              #\n","    ############################################################################\n","    return model\n","\n","learning_rate = 5e-4\n","def optimizer_init_fn():\n","    optimizer = None\n","    ############################################################################\n","    # TODO: Complete the implementation of model_fn.                           #\n","    ############################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","    pass\n","\n","    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    ############################################################################\n","    #                           END OF YOUR CODE                               #\n","    ############################################################################\n","    return optimizer\n","\n","train_part34(model_init_fn, optimizer_init_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hmkfljZuzQ_x"},"source":["Você também pode treinar esse modelo utilizando o método pronto da API do TensorFlow."]},{"cell_type":"code","metadata":{"id":"zWlS3EzazQ_y"},"source":["model = model_init_fn()\n","model.compile(optimizer='sgd',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n","model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n","model.evaluate(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"451wYP6xzQ_z"},"source":["##  API Funcional\n","### Demonstração com uma Rede de Duas Camadas \n","\n","Nas seções anteriores desse *notebook*, vimos como usar `tf.keras.Sequential` para empilhar camadas de forma a se construir rapidamente modelos simples. Porém isto possui um custo: a perda de flexibilidade.\n","\n","Em alguns casos, deseja-se escrever modelos complexos que possuem um fluxo de dados não-sequencial: uma camada pode ter **múltiplas entradas e/ou saídas**, como, por exemplo, concatenar as saídas de duas camadas anteriores para se fornecer como entrada para uma próxima! Alguns exemplos disso são conexões residuais e os blocos densos da ResNet e da DenseNet, respectivamente.\n","\n","Nesses casos, pode-se utilizar a API funcional do Keras para se escrever modelos com topologias complexas como:\n","\n"," 1. Modelos com múltiplas entradas\n"," 2. Modelos com múltiplas saídas\n"," 3. Modelos com camadas compartilhadas (a mesma camada chamada várias vezes)\n"," 4. Modelos com fluxos de dados não-sequenciais (p.ex. conexões residuais)\n","\n","Para a escrita de um modelo com a API funcional, você deve criar uma instância de `tf.keras.Model` e explicitamente fornecer os tensores de entrada e de saída para seu modelo. "]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"GU8Vr1uCzQ_0"},"source":["def two_layer_fc_functional(input_shape, hidden_size, num_classes):  \n","    initializer = tf.initializers.VarianceScaling(scale=2.0)\n","    inputs = tf.keras.Input(shape=input_shape)\n","    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n","    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n","                                 kernel_initializer=initializer)(flattened_inputs)\n","    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n","                             kernel_initializer=initializer)(fc1_output)\n","\n","    # Instantiate the model given inputs and outputs.\n","    model = tf.keras.Model(inputs=inputs, outputs=scores)\n","    return model\n","\n","def test_two_layer_fc_functional():\n","    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n","    input_size, hidden_size, num_classes = 50, 42, 10\n","    input_shape = (50,)\n","    \n","    x = tf.zeros((64, input_size))\n","    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n","    \n","    with tf.device(device):\n","        scores = model(x)\n","        print(scores.shape)\n","        \n","test_two_layer_fc_functional()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UGiKqnqpzQ_2"},"source":["### Uso da API Keras Funcional: Treinando uma de Duas Camadas\n","\n","Agora você pode treinar a rede de duas camadas construída (ver acima) utilizando a API funcional.\n","\n","Você não precisa ajustar nenhum hiperparâmetro, mas (mesmo assim) deve alcançar uma acurácia de validação acima de 40% após uma época de treinamento."]},{"cell_type":"code","metadata":{"id":"vN4YGTlkzQ_2"},"source":["input_shape = (32, 32, 3)\n","hidden_size, num_classes = 4000, 10\n","learning_rate = 1e-2\n","\n","def model_init_fn():\n","    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n","\n","def optimizer_init_fn():\n","    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n","\n","train_part34(model_init_fn, optimizer_init_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SyLho7rizQ_5"},"source":["# Desafio Final: Treinar uma ConvNet sobre o Dataset CIFAR-10\n","\n","Nesta seção você poderá experimentar com uma arquitetura de ConvNet que desejar treinar sobre o dataset CIFAR-10.\n","\n","Você deve experimentar diferentes arquiteturas, hoperparâmetros, funções de perda, regularização ou quaisquer outros recursos que deseje para treinar um modelo que alcance **pelo menos 70%** de acurácia sobre o conjunto de **validação** dentro de 10 épocas.\n","\n","Você pode utilizar as funções de treinamento prontas da API, a função `train_part34` dada acima ou mesmo implementar sua própria função.\n","\n","Ao final, é importante que você consiga descrever o que você fez para alcançar seu resultado!\n","\n","### Algumas ideias que você pode experimentar:\n","- **Tamanho de filtros**: Acima foram usados filtros 5x5 e 3x3; esses tamanhos são ideiais?\n","- **Número de filtros**: Acima foram usados 16 e 32 filtros. Será que um aumento ou redução dessas quantidades produziria um resultado melhor?\n","- **Agrupamento (*Pooling*)**: Acima não se utilizou de nenhuma camada de agrupamento (*pooling*). Isso poderia melhorar o modelo?\n","- **Normalização**: Será que o modelo seria melhor se fosse adotada alguma técnica de normalização, como, por exemplo, *batch normalization*?\n","- **Arquitetura da Rede**: A ConvNet anterior possui apenas 3 camadas. Um modelo mais profundo teria resultados melhores?\n","- **Agrupamento Médio Global (*Global average pooling*)**: Se, ao invés de achatamento (*flattening*) depois da última camada convolucional, fosse utilizado um agrupamento médio global (*global average pooling*) o resultado seria melhor? Essa estratágia é usada por exemplo na GoogLeNet e na ResNet.\n","- **Regularização**: Será que o uso de alguma forma de regularização (como, decaimento de taxa e *dropout*, por exemplo) melhoria o resultado do modelo?\n","\n","### NOTA: *Batch Normalization / Dropout*\n","Se você for utilizar *batch normalization* e *drpout*, lembre-se de fornecer o parâmetro `is_training=True` caso utilize o método de treinamento  `train_part34()`. Camadas **BatchNorm** e **Dropout** possuem comportamentos diferentes durante o treinamento e seu posterior uso na inferência.\n","`training` é um argumento específico reservado para esse propósito em qualquer função `call()` da API  `tf.keras.Model`. Mais informações sobre isso em https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods\n","https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods\n","\n","### Dicas para Treinamento\n","Para cada arquitetura de rede que você experimentar, você deve ajustar a taxa de aprendizado e demais hiperparâmetros. Quando realizar isso, algumas aspectos devem ser considerados:\n","\n","- Se os hiperparâmetros são bons, você deve observar melhorias dentro de algumas centenas de iterações\n","- Lembre-se de usar uma abordagem de refinamento sucessivos (*coarse-to-fine*) nos ajustes de hiperparâmetros: inicie com intervalos grandes e faça poucas iterações de forma a determinar combinações promissoras para serem exploradas mais cuidadosamente a seguir \n","- Uma vez que tenha encontrado alguns conjuntos de parâmetros que parecem funcionar, faça uma busca mais refinada em torno desses valores de parâmetros. Talvez seja necessário treinar por um número maior de épocas\n","- Você deve usar o conjunto de validação para ajuste de hiperparâmetros (**nunca o conjunto de teste!**), e deixar reservado o conjunto de teste para avaliar sua arquitetura final obtida com os melhores parâmetros selecionados por meio do conjunto de validação\n","\n","### Indo adiante e além...\n","Caso você deseje existem inúmeros recursos e estratégias adicionais que você pode experimentar para melhorar a performance de seu modelo. Você **não precisa** implementar nenhuma delas, mas não deixe a diversão de lado, caso tenha tempo disponível!\n","\n","- Otimizadores alternativos: você pode experimentar usar Adam, Adagrad, RMSprop, etc.\n","- Funções de ativação alternativas como *Leaky ReLU*, *Parametric ReLU*, ELU, ou MaxOut.\n","- Construir conjuntos de modelos (*model ensembles*)\n","- Realizar *data augmentation*\n","- Explorar novas arquiteturas\n","  - [ResNets](https://arxiv.org/abs/1512.03385) em que a entrada da camada anterior é adicionada a saída\n","  - [DenseNets](https://arxiv.org/abs/1608.06993) em que entradas de camadas anteriores são concatenadas\n","  - [Eis um *blog* interessante com mais ideias](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n","  \n","### Tenha uma boa (e divertida) experiência de treinamento! "]},{"cell_type":"code","metadata":{"id":"open_ended_accuracy"},"source":["class CustomConvNet(tf.keras.Model):\n","    def __init__(self):\n","        super(CustomConvNet, self).__init__()\n","        ############################################################################\n","        # TODO: Construct a model that performs well on CIFAR-10                   #\n","        ############################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","        pass\n","\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ############################################################################\n","        #                            END OF YOUR CODE                              #\n","        ############################################################################\n","    \n","    def call(self, input_tensor, training=False):\n","        ############################################################################\n","        # TODO: Construct a model that performs well on CIFAR-10                   #\n","        ############################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","        pass\n","\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ############################################################################\n","        #                            END OF YOUR CODE                              #\n","        ############################################################################\n","        return x\n","\n","\n","print_every = 700\n","num_epochs = 10\n","\n","model = CustomConvNet()\n","\n","def model_init_fn():\n","    return CustomConvNet()\n","\n","def optimizer_init_fn():\n","    learning_rate = 1e-3\n","    return tf.keras.optimizers.Adam(learning_rate) \n","\n","train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"],"execution_count":null,"outputs":[]}]}