{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unidade03_keras_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGLweQ7L56Me"
      },
      "source": [
        "**MNIST Database**\n",
        "\n",
        "Rede Neural Convolucional para classificar imagens do MNIST dataset.\n",
        "\n",
        "Possui 70.000 imagens de dígitos escritos à mão\n",
        "As dimensões das imagens são 28x28\n",
        "Imagens em escala de cinza"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl456zCb96LJ"
      },
      "source": [
        "# check whether GPU is provided\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1MlKlym6Pq1"
      },
      "source": [
        "1. Load MNIST Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTUMIVuW5rwA"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# use Keras to import pre-shuffled MNIST database\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"The MNIST database has a training set of %d examples.\" % len(X_train))\n",
        "print(\"The MNIST database has a test set of %d examples.\" % len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cMDu8926UUS"
      },
      "source": [
        "2. Visualize as seis primeiras imagens de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQjC4O_m6V9-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "# plot first six training images\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "for i in range(6):\n",
        "    ax = fig.add_subplot(1, 6, i+1, xticks=[], yticks=[])\n",
        "    ax.imshow(X_train[i], cmap='gray')\n",
        "    ax.set_title(str(y_train[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5Nms_v66YCD"
      },
      "source": [
        "3. Visualizar a imagem com maior detalhe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdzazCVW6aGi"
      },
      "source": [
        "def visualize_input(img, ax):\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    width, height = img.shape\n",
        "    thresh = img.max()/2.5\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n",
        "                        horizontalalignment='center',\n",
        "                        verticalalignment='center',\n",
        "                        color='white' if img[x][y]<thresh else 'black')\n",
        "\n",
        "fig = plt.figure(figsize = (12,12)) \n",
        "ax = fig.add_subplot(111)\n",
        "visualize_input(X_train[0], ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4e26DrT6b3m"
      },
      "source": [
        "4. Pré-processar imagens de entrada: redimensionar as imagens dividindo cada pixel em cada imagem por 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHeiPVoy6eBD"
      },
      "source": [
        "# rescale to have values within 0 - 1 range [0,255] --> [0,1]\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255 \n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EMrlVZR6gx9"
      },
      "source": [
        "5. Preprocessamento dos labels: Encode Categorical Integer Labels Using a One-Hot Scheme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K99B-w076j6X"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "num_classes = 10 \n",
        "# print first ten (integer-valued) training labels\n",
        "print('Integer-valued labels:')\n",
        "print(y_train[:10])\n",
        "\n",
        "# one-hot encode the labels\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# print first ten (one-hot) training labels\n",
        "print('One-hot labels:')\n",
        "print(y_train[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cVG5b-Y6oQ4"
      },
      "source": [
        "6. Reshape data to fit our CNN (and input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iepDGq656qFD"
      },
      "source": [
        "# input image dimensions 28x28 pixel images. \n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "print('input_shape: ', input_shape)\n",
        "print('x_train shape:', X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1LuufmX6sGq"
      },
      "source": [
        "7. Define the Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpVEU_Sm6uFj"
      },
      "source": [
        "filters - o número de filtros.\n",
        "\n",
        "kernel_size - Número que especifica a altura e a largura da janela de convolução.\n",
        "\n",
        "strides - O strides da convolução. Se você não especificar nada, strides será definido como 1.\n",
        "\n",
        "padding - 'valid' ou 'same'. Se você não especificar nada, o padding será definido como 'valid'.\n",
        "\n",
        "activation  - Normalmente 'relu'. Se você não especificar nada, nenhuma ativação será aplicada. Fortemente recomendado adicionar uma função de ativação ReLU a cada camada convolucional da redes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7ubpkEt7XRk"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# build the model object\n",
        "model = Sequential()\n",
        "\n",
        "# CONV_1: add CONV layer with RELU activation and depth = 32 kernels\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), padding='same',activation='relu',input_shape=(28,28,1)))\n",
        "# POOL_1: downsample the image to choose the best features \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# CONV_2: here we increase the depth to 64\n",
        "model.add(Conv2D(64, (3, 3),padding='same', activation='relu'))\n",
        "# POOL_2: more downsampling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# flatten since too many dimensions, we only want a classification output\n",
        "model.add(Flatten())\n",
        "\n",
        "# FC_1: fully connected to get all relevant data\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# FC_2: output a softmax to squash the matrix into output probabilities for the 10 classes\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ1Eiqce7fSy"
      },
      "source": [
        "8. Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0mad3_V7gQu"
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilTTmcAp7j09"
      },
      "source": [
        "9. Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1lw0d4t7lf5"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint   \n",
        "\n",
        "# train the model\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, \n",
        "                               save_best_only=True)\n",
        "hist = model.fit(X_train, y_train, batch_size=32, epochs=12,\n",
        "          validation_data=(X_test, y_test), callbacks=[checkpointer], \n",
        "          verbose=2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXZYf_J47ose"
      },
      "source": [
        "10. Load the Model with the Best Classification Accuracy on the Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGAcZdIN7pL6"
      },
      "source": [
        "# load the weights that yielded the best validation accuracy\n",
        "model.load_weights('model.weights.best.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2Kdy5b_7rXS"
      },
      "source": [
        "11. Calculate the Classification Accuracy on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A24K6oDd7q50"
      },
      "source": [
        "# evaluate test accuracy\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "# print test accuracy\n",
        "print('Test accuracy: %.4f%%' % accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvqGgKgUrWGB"
      },
      "source": [
        "print(y_test[1])\n",
        "x = X_test[1]\n",
        "x = x.reshape(1, img_rows, img_cols, 1)\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "prob = model.predict(x)\n",
        "preds = np.argmax(model.predict(x), axis=-1)\n",
        "\n",
        "print(prob, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlPoWMSJKoHB"
      },
      "source": [
        "Referência: Mohamed Elgendy. Deep Learning for Vision Systems. 2020 (estimated)\n"
      ]
    }
  ]
}